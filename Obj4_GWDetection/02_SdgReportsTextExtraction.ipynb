{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Extraction from SDG reports (PDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/luca/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import fitz # PyMuPDF\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Ensure NLTK 'punkt' resource is downloaded\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pdf  = '../Data/Input/SDGs'\n",
    "fname_out = '../Data/Output/SdgReportSentences.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function: Get count of words (only alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnt(text):\n",
    "    cnt = 0\n",
    "    for word in text.split():\n",
    "        if word.isalpha():\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function: Get text from blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Mytext(block_lst):\n",
    "\n",
    "    MIN_WORD_CNT = 10 \n",
    "    \n",
    "    text_lst = []\n",
    "    for block in block_lst:\n",
    "        if block[6] != 0: continue # block_type: 0 = text\n",
    "    \n",
    "        text = block[4]\n",
    "        text = text.replace('fi ', 'fi') # PyMuPDF(fitz) bug fix: 'fi ' --> 'fi'\n",
    "    \n",
    "        if get_cnt(text) < MIN_WORD_CNT: continue # Delete sentences with less than MIN_WORD_CNT(10) \n",
    "    \n",
    "        text_lst.append(text.replace('-\\n', '')) # To ensures that any hyphenated words split across lines are joined properly in the resulting text.\n",
    "        \n",
    "    return ('\\n'.join(text_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function: Get sentences from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(fname, skip_page = (0,)):\n",
    " \n",
    "    doc = fitz.open(fname)\n",
    "    \n",
    "    sent_lst = []\n",
    "    for page_no, page in enumerate(doc):\n",
    "\n",
    "        # Skip page\n",
    "        if page_no+1 in skip_page: continue\n",
    "        \n",
    "        block_lst = page.get_text('blocks') #####\n",
    "        text = get_Mytext(block_lst)\n",
    "    \n",
    "        for i, sentence in enumerate(sent_tokenize(text)):\n",
    "            r_sent = ' '.join(sentence.split()) # Delete '\\n', '\\t' and strip\n",
    "            sent_lst.append(r_sent)\n",
    "            \n",
    "    doc.close()\n",
    "\n",
    "    return sent_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function: Generate document (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_document(doc_id, fname, sent_lst):\n",
    "\n",
    "    res_df = pd.DataFrame(\n",
    "        {\n",
    "            'doc_id': doc_id,\n",
    "            'fname': fname,\n",
    "            'sentence': sent_lst\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_directories(top_directory):\n",
    "    \"\"\"This function iterates across \n",
    "    every directory from the top directory.\"\"\"\n",
    "\n",
    "    for root, dirs, files in os.walk(top_directory):\n",
    "        print(f'Current directory: {root}')\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: ../Data/Input/SDGs\n",
      "Current directory: ../Data/Input/SDGs/03_Equity\n",
      "Current directory: ../Data/Input/SDGs/04_Social Development\n",
      "Current directory: ../Data/Input/SDGs/05_Resources\n",
      "Current directory: ../Data/Input/SDGs/06_Environments\n",
      "Current directory: ../Data/Input/SDGs/01_Life\n",
      "Current directory: ../Data/Input/SDGs/02_Economic and Technological Development\n"
     ]
    }
   ],
   "source": [
    "iterate_directories(path_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function: Read PDF file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filelist(path):\n",
    "\n",
    "    # Create empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    # Iterate through the sorted file list\n",
    "    for idx, fname in enumerate(file_list):\n",
    "    # Read file list (directory)\n",
    "    # for idx, fname in enumerate(os.listdir(path)):\n",
    "        p_fname = os.path.join(path, fname)\n",
    "        print('path + fname >>>', p_fname)\n",
    "        \n",
    "        if p_fname.split('.')[-1] != 'pdf': continue # Check for 'pdf' extension\n",
    "        print('fname >>>',fname)\n",
    "    \n",
    "        doc_id = int(idx)\n",
    "        \n",
    "        print(f'doc_id = [{doc_id}], fname = [{fname}]')\n",
    "        print('')\n",
    "    \n",
    "        sent_lst = get_sentence(p_fname)\n",
    "        df_doc   = gen_document(doc_id, fname, sent_lst)\n",
    "        \n",
    "        df = pd.concat([df,df_doc])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = read_filelist(path_pdf)\n",
    "print('==== End of jobs ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fname_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
