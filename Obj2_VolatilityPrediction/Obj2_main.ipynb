{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Two - Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict stock market volatility using ESG-related news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [Errno 8]\n",
      "[nltk_data]     nodename nor servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Granger's casuality test library\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "# Import VADER for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_curve, auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate the daily market returns time series and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.380</td>\n",
       "      <td>13.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>13.28</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.370</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-03</td>\n",
       "      <td>13.65</td>\n",
       "      <td>13.25</td>\n",
       "      <td>13.680</td>\n",
       "      <td>13.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>13.21</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13.950</td>\n",
       "      <td>13.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>13.28</td>\n",
       "      <td>13.27</td>\n",
       "      <td>13.395</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>330.50</td>\n",
       "      <td>328.50</td>\n",
       "      <td>331.100</td>\n",
       "      <td>326.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>333.50</td>\n",
       "      <td>331.70</td>\n",
       "      <td>333.900</td>\n",
       "      <td>330.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>335.00</td>\n",
       "      <td>333.80</td>\n",
       "      <td>338.000</td>\n",
       "      <td>333.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>340.60</td>\n",
       "      <td>336.50</td>\n",
       "      <td>340.600</td>\n",
       "      <td>336.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>341.20</td>\n",
       "      <td>341.50</td>\n",
       "      <td>342.000</td>\n",
       "      <td>338.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company  symbol        date   close    open     high      low\n",
       "0      Ford       F  2024-04-01   13.29   13.33   13.380   13.140\n",
       "1      Ford       F  2024-04-02   13.28   13.16   13.370   13.090\n",
       "2      Ford       F  2024-04-03   13.65   13.25   13.680   13.230\n",
       "3      Ford       F  2024-04-04   13.21   13.90   13.950   13.170\n",
       "4      Ford       F  2024-04-05   13.28   13.27   13.395   13.090\n",
       "..      ...     ...         ...     ...     ...      ...      ...\n",
       "955   Tesco  TSCO.L  2024-08-09  330.50  328.50  331.100  326.200\n",
       "956   Tesco  TSCO.L  2024-08-12  333.50  331.70  333.900  330.880\n",
       "957   Tesco  TSCO.L  2024-08-13  335.00  333.80  338.000  333.400\n",
       "958   Tesco  TSCO.L  2024-08-14  340.60  336.50  340.600  336.400\n",
       "959   Tesco  TSCO.L  2024-08-15  341.20  341.50  342.000  338.596\n",
       "\n",
       "[960 rows x 7 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load price data\n",
    "prices_file_path = '../Data/Input/Eikon/refinitiv_prices_raw.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "prices_df = pd.read_csv(prices_file_path)\n",
    "\n",
    "prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "   company symbol       date  close   open   high      low\n",
      "22    Ford      F 2024-05-01  12.20  12.16  12.43  12.1500\n",
      "23    Ford      F 2024-05-02  12.49  12.40  12.55  12.3600\n",
      "24    Ford      F 2024-05-03  12.43  12.64  12.76  12.3900\n",
      "25    Ford      F 2024-05-06  12.50  12.54  12.62  12.4575\n",
      "26    Ford      F 2024-05-07  12.17  12.40  12.45  12.0850\n"
     ]
    }
   ],
   "source": [
    "# Let's filter the dataset to match the dates of the available news stories \n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "\n",
    "# Define the date range for filtering\n",
    "start_date = '2024-05-01'\n",
    "end_date = '2024-07-31'\n",
    "\n",
    "# Convert string to datetime object\n",
    "date_format = \"%Y-%m-%d\"\n",
    "start_date = datetime.strptime(start_date, date_format)\n",
    "end_date = datetime.strptime(end_date, date_format)\n",
    "\n",
    "delta = (end_date-start_date)\n",
    "N = delta.days + 1\n",
    "print(N)\n",
    "\n",
    "# Filter the DataFrame to keep rows between 1st May 2024 and 31st July 2024\n",
    "stock_performance_df = prices_df[(prices_df['date'] >= start_date) & (prices_df['date'] <= end_date)]\n",
    "\n",
    "# Display the filtered data\n",
    "print(stock_performance_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.4300</td>\n",
       "      <td>12.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>12.49</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.5500</td>\n",
       "      <td>12.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>12.43</td>\n",
       "      <td>12.64</td>\n",
       "      <td>12.7600</td>\n",
       "      <td>12.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12.6200</td>\n",
       "      <td>12.4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>12.17</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.4500</td>\n",
       "      <td>12.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>325.60</td>\n",
       "      <td>325.60</td>\n",
       "      <td>327.1000</td>\n",
       "      <td>323.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>327.10</td>\n",
       "      <td>325.10</td>\n",
       "      <td>328.6000</td>\n",
       "      <td>323.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>330.90</td>\n",
       "      <td>330.00</td>\n",
       "      <td>333.7000</td>\n",
       "      <td>328.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>331.70</td>\n",
       "      <td>330.00</td>\n",
       "      <td>332.8000</td>\n",
       "      <td>328.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>331.60</td>\n",
       "      <td>331.90</td>\n",
       "      <td>334.2996</td>\n",
       "      <td>330.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company  symbol       date   close    open      high       low\n",
       "22     Ford       F 2024-05-01   12.20   12.16   12.4300   12.1500\n",
       "23     Ford       F 2024-05-02   12.49   12.40   12.5500   12.3600\n",
       "24     Ford       F 2024-05-03   12.43   12.64   12.7600   12.3900\n",
       "25     Ford       F 2024-05-06   12.50   12.54   12.6200   12.4575\n",
       "26     Ford       F 2024-05-07   12.17   12.40   12.4500   12.0850\n",
       "..      ...     ...        ...     ...     ...       ...       ...\n",
       "944   Tesco  TSCO.L 2024-07-25  325.60  325.60  327.1000  323.4000\n",
       "945   Tesco  TSCO.L 2024-07-26  327.10  325.10  328.6000  323.3490\n",
       "946   Tesco  TSCO.L 2024-07-29  330.90  330.00  333.7000  328.1630\n",
       "947   Tesco  TSCO.L 2024-07-30  331.70  330.00  332.8000  328.4000\n",
       "948   Tesco  TSCO.L 2024-07-31  331.60  331.90  334.2996  330.5000\n",
       "\n",
       "[636 rows x 7 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily market return on day t is calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "r_{t} = ln \\left(\\frac{CLOSE_{t}}{CLOSE_{t-1}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $CLOSE_{t}$ is the closing price on day t and $CLOSE_{t-1}$ is the previous day closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by company and date to maintain the proper order for each company\n",
    "stock_performance_df = stock_performance_df.sort_values(by=['company', 'date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    company symbol       date  close   open    high    low  daily_return\n",
      "502    Asda    WMT 2024-05-01  58.85  59.31  59.410  58.72           NaN\n",
      "503    Asda    WMT 2024-05-02  59.71  58.94  59.885  58.58      0.014508\n",
      "504    Asda    WMT 2024-05-03  59.82  59.62  59.980  59.14      0.001841\n",
      "505    Asda    WMT 2024-05-06  59.87  60.00  60.000  59.39      0.000835\n",
      "506    Asda    WMT 2024-05-07  60.62  60.17  60.800  60.05      0.012449\n"
     ]
    }
   ],
   "source": [
    "# Calculate daily market return using the formula: r_t = log(CLOSE_t / CLOSE_t-1)\n",
    "stock_performance_df['daily_return'] = stock_performance_df.groupby('company', group_keys=False)['close'].apply(\n",
    "    lambda x: np.log(x / x.shift(1))\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(stock_performance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>58.85</td>\n",
       "      <td>59.31</td>\n",
       "      <td>59.410</td>\n",
       "      <td>58.7200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>59.71</td>\n",
       "      <td>58.94</td>\n",
       "      <td>59.885</td>\n",
       "      <td>58.5800</td>\n",
       "      <td>0.014508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>59.82</td>\n",
       "      <td>59.62</td>\n",
       "      <td>59.980</td>\n",
       "      <td>59.1400</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>59.87</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.000</td>\n",
       "      <td>59.3900</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>60.62</td>\n",
       "      <td>60.17</td>\n",
       "      <td>60.800</td>\n",
       "      <td>60.0500</td>\n",
       "      <td>0.012449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>195.25</td>\n",
       "      <td>197.43</td>\n",
       "      <td>197.430</td>\n",
       "      <td>193.7300</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>192.52</td>\n",
       "      <td>190.74</td>\n",
       "      <td>192.840</td>\n",
       "      <td>190.5100</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>192.48</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.200</td>\n",
       "      <td>191.8067</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>193.11</td>\n",
       "      <td>194.96</td>\n",
       "      <td>195.480</td>\n",
       "      <td>192.2650</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>193.55</td>\n",
       "      <td>194.18</td>\n",
       "      <td>194.890</td>\n",
       "      <td>192.9000</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company symbol       date   close    open     high       low  daily_return\n",
       "502    Asda    WMT 2024-05-01   58.85   59.31   59.410   58.7200           NaN\n",
       "503    Asda    WMT 2024-05-02   59.71   58.94   59.885   58.5800      0.014508\n",
       "504    Asda    WMT 2024-05-03   59.82   59.62   59.980   59.1400      0.001841\n",
       "505    Asda    WMT 2024-05-06   59.87   60.00   60.000   59.3900      0.000835\n",
       "506    Asda    WMT 2024-05-07   60.62   60.17   60.800   60.0500      0.012449\n",
       "..      ...    ...        ...     ...     ...      ...       ...           ...\n",
       "464  Toyota     TM 2024-07-25  195.25  197.43  197.430  193.7300     -0.009938\n",
       "465  Toyota     TM 2024-07-26  192.52  190.74  192.840  190.5100     -0.014081\n",
       "466  Toyota     TM 2024-07-29  192.48  193.00  193.200  191.8067     -0.000208\n",
       "467  Toyota     TM 2024-07-30  193.11  194.96  195.480  192.2650      0.003268\n",
       "468  Toyota     TM 2024-07-31  193.55  194.18  194.890  192.9000      0.002276\n",
       "\n",
       "[636 rows x 8 columns]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Volatility\n",
    "\n",
    "The volatility of the stock market index is calculated within a defined time window (e.g., previous 90 days):\n",
    "\n",
    "\\begin{equation}\n",
    "Vol = \\sqrt{\\frac{1}{N}\\sum_{t=1}^{N}(r_{t}-\\bar{r})^2} \\cdot \\sqrt{252}\n",
    "\\end{equation}\n",
    "\n",
    "where N is the total number of days during a window time of observations (eg, 30 days), and 252 is the total number of trading days in a single year;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  volatility quartile\n",
      "0             Asda    0.187419        1\n",
      "1             Ford    0.477228        3\n",
      "2  Marks & Spencer    0.250589        2\n",
      "3            Ocado    0.745336        4\n",
      "4         Polestar    1.047160        4\n",
      "5       Sainsburys    0.195476        1\n",
      "6       Stellantis    0.294795        3\n",
      "7            Tesco    0.120855        1\n",
      "8            Tesla    0.566548        4\n",
      "9           Toyota    0.224128        2\n"
     ]
    }
   ],
   "source": [
    "def calculate_volatility(df):\n",
    "    # Group by company to calculate volatility for each stock\n",
    "    volatility_df = df.groupby('company').apply(lambda x: calculate_stock_volatility(x))\n",
    "    \n",
    "    # Reset the index \n",
    "    volatility_df = volatility_df.reset_index(drop=True)\n",
    "    \n",
    "    # Calculate quartiles\n",
    "    quartiles = np.percentile(volatility_df['volatility'], [0, 25, 50, 75, 100])\n",
    "    \n",
    "    # Add quartile information to the DataFrame\n",
    "    volatility_df['quartile'] = pd.cut(volatility_df['volatility'], bins=quartiles, labels=[1, 2, 3, 4], include_lowest=True)\n",
    "\n",
    "    return volatility_df\n",
    "\n",
    "def calculate_stock_volatility(stock_df):\n",
    "    # Number of trading days (rows)\n",
    "    N = len(stock_df)\n",
    "    \n",
    "    # Mean of daily returns (r̄)\n",
    "    mean_return = stock_df['daily_return'].mean()\n",
    "    \n",
    "    # Variance calculation: \n",
    "    variance = np.sum((stock_df['daily_return'] - mean_return) ** 2) / N\n",
    "    \n",
    "    # Daily volatility: sqrt(variance)\n",
    "    daily_volatility = np.sqrt(variance)\n",
    "    \n",
    "    # Annual volatility: daily_volatility * sqrt(252)\n",
    "    annual_volatility = daily_volatility * np.sqrt(252)\n",
    "    \n",
    "    # Return the company and its calculated volatility\n",
    "    return pd.Series({'company': stock_df['company'].iloc[0], 'volatility': annual_volatility})\n",
    "\n",
    "\n",
    "volatility_results = calculate_volatility(stock_performance_df)\n",
    "\n",
    "# Display the calculated volatility and quartile for each company\n",
    "print(volatility_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>volatility</th>\n",
       "      <th>quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>1.047160</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>0.745336</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford</td>\n",
       "      <td>0.477228</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>0.294795</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>0.250589</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>0.224128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>0.195476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>0.187419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>0.120855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company  volatility quartile\n",
       "4         Polestar    1.047160        4\n",
       "3            Ocado    0.745336        4\n",
       "8            Tesla    0.566548        4\n",
       "1             Ford    0.477228        3\n",
       "6       Stellantis    0.294795        3\n",
       "2  Marks & Spencer    0.250589        2\n",
       "9           Toyota    0.224128        2\n",
       "5       Sainsburys    0.195476        1\n",
       "0             Asda    0.187419        1\n",
       "7            Tesco    0.120855        1"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by 'volatility' in descending order\n",
    "volatility_results = volatility_results.sort_values(by='volatility', ascending=False)\n",
    "volatility_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run sentiment Analysis of the ESG news stories using VADER and set up the daily sentiment score time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca  accesswire  july 29 2024  the ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny  accesswire  july 29 2024  br...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc is inves...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv\\nalaska energy...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july  29 2024  globe newswire  ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>tesco the uks largest supermarket chain has sp...</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>tesco has been accused of giving struggling wo...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>tesco boss ken murphy has seen his pay deal mo...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>tesco has apologised after a black publisher s...</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>tesco ireland the republic of ireland based su...</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story        date company  \\\n",
       "0    los angeles ca  accesswire  july 29 2024  the ...  2024-07-29    Ford   \n",
       "1    new york city ny  accesswire  july 29 2024  br...  2024-07-29    Ford   \n",
       "2    ford alert bragar eagel amp squire pc is inves...  2024-07-29    Ford   \n",
       "3    first atlantic nickel corp fanv\\nalaska energy...  2024-07-29    Ford   \n",
       "4    palm beach fla july  29 2024  globe newswire  ...  2024-07-29    Ford   \n",
       "..                                                 ...         ...     ...   \n",
       "985  tesco the uks largest supermarket chain has sp...  2024-05-15   Tesco   \n",
       "986  tesco has been accused of giving struggling wo...  2024-05-14   Tesco   \n",
       "987  tesco boss ken murphy has seen his pay deal mo...  2024-05-14   Tesco   \n",
       "988  tesco has apologised after a black publisher s...  2024-05-20   Tesco   \n",
       "989  tesco ireland the republic of ireland based su...  2024-05-03   Tesco   \n",
       "\n",
       "             ticker  \n",
       "0               esg  \n",
       "1               esg  \n",
       "2               esg  \n",
       "3               esg  \n",
       "4               esg  \n",
       "..              ...  \n",
       "985      governance  \n",
       "986      governance  \n",
       "987      governance  \n",
       "988  sustainability  \n",
       "989  sustainability  \n",
       "\n",
       "[990 rows x 4 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Pre-Processed ESG stories data from Objective One\n",
    "stories_file_path = '../Data/Output/news_df.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "news_df = pd.read_csv(stories_file_path)\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's initialise the 'stop words' function for English \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july 29 2024 schall ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july 29 2024 brons...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july 29 2024 globe newswire fin...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july 29 2024 schall ...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july 29 2024 brons...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july 29 2024 globe newswire fin...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove 'stop words' from the stories\n",
    "\n",
    "news_df['story'] = news_df['story'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop]))\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's lemmatise the content of the 'story' column\n",
    "\n",
    "for index, row in news_df.iterrows():\n",
    "    words = nltk.word_tokenize(row['story'])\n",
    "\n",
    "    # Lemmatise each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    # Update the 'story' column with the lemmatised text\n",
    "    news_df.at[index, 'story'] = lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july 29 2024 schall ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july 29 2024 brons...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july 29 2024 globe newswire fin...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july 29 2024 schall ...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july 29 2024 brons...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july 29 2024 globe newswire fin...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove numbers from the 'story' column using regular expressions\n",
    "\n",
    "for index, row in news_df.iterrows():\n",
    "    row_text = re.sub(r'\\d+', '', row['story'])\n",
    "    news_df.at[index, 'story'] = row_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july   schall law fi...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july   bronstein g...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july   globe newswire financial...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july   schall law fi...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july   bronstein g...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july   globe newswire financial...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove non-alphanumeric characters from the column 'story'\n",
    "def remove_symbols(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]','', text)\n",
    "    return cleaned_text\n",
    "\n",
    "news_df['story'] = news_df['story'].apply(lambda x: remove_symbols(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july   schall law fi...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july   bronstein g...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july   globe newswire financial...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july   schall law fi...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july   bronstein g...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july   globe newswire financial...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove first names of ppl from the news articles\n",
    "\n",
    "def remove_first_names(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_text = ' '.join([token.text if token.ent_type_ != 'person' else '' for token in doc])\n",
    "    return ' '.join(filtered_text.split())\n",
    "\n",
    "for index, row in news_df.iterrows():\n",
    "    # Let's remove first names of ppl using spaCy NER\n",
    "    news_df.at[index, 'story'] = remove_first_names(row['story'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july schall law firm...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july bronstein gew...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july globe newswire financialne...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july schall law firm...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july bronstein gew...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july globe newswire financialne...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean ESG-related news \n",
    "news_df.to_csv('../Data/Output/obj2_ESG_news_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july schall law firm...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july bronstein gew...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july globe newswire financialne...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>tesco uk largest supermarket chain sparked con...</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>tesco accused giving struggling worker slap fa...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>tesco bos ken murphy seen pay deal double almo...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>tesco apologised black publisher say racially ...</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.6794</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>tesco ireland republic ireland based subsidiar...</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story        date company  \\\n",
       "0    los angeles ca accesswire july schall law firm...  2024-07-29    Ford   \n",
       "1    new york city ny accesswire july bronstein gew...  2024-07-29    Ford   \n",
       "2    ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3    first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4    palm beach fla july globe newswire financialne...  2024-07-29    Ford   \n",
       "..                                                 ...         ...     ...   \n",
       "985  tesco uk largest supermarket chain sparked con...  2024-05-15   Tesco   \n",
       "986  tesco accused giving struggling worker slap fa...  2024-05-14   Tesco   \n",
       "987  tesco bos ken murphy seen pay deal double almo...  2024-05-14   Tesco   \n",
       "988  tesco apologised black publisher say racially ...  2024-05-20   Tesco   \n",
       "989  tesco ireland republic ireland based subsidiar...  2024-05-03   Tesco   \n",
       "\n",
       "             ticker    neg    neu    pos  compound sentiment  \n",
       "0               esg  0.106  0.764  0.130    0.5719  positive  \n",
       "1               esg  0.067  0.854  0.079    0.1027  positive  \n",
       "2               esg  0.066  0.783  0.150    0.9552  positive  \n",
       "3               esg  0.037  0.808  0.155    0.9995  positive  \n",
       "4               esg  0.035  0.811  0.154    0.9994  positive  \n",
       "..              ...    ...    ...    ...       ...       ...  \n",
       "985      governance  0.127  0.685  0.187    0.9451  positive  \n",
       "986      governance  0.116  0.688  0.196    0.9896  positive  \n",
       "987      governance  0.060  0.733  0.207    0.9886  positive  \n",
       "988  sustainability  0.134  0.728  0.138   -0.6794  negative  \n",
       "989  sustainability  0.009  0.784  0.207    0.9946  positive  \n",
       "\n",
       "[990 rows x 9 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to apply VADER and get sentiment scores\n",
    "def apply_vader_sentiment(text):\n",
    "    # Get the sentiment scores from VADER\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply VADER sentiment analysis to the \"story\" column\n",
    "news_df['vader_sentiment'] = news_df['story'].apply(apply_vader_sentiment)\n",
    "\n",
    "# Split the sentiment scores into separate columns (optional)\n",
    "news_df = pd.concat([news_df.drop(['vader_sentiment'], axis=1), news_df['vader_sentiment'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# Define a function to classify sentiment based on the 'compound' score\n",
    "def classify_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the classify_sentiment function to create a new 'sentiment' column\n",
    "news_df['sentiment'] = news_df['compound'].apply(classify_sentiment)\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the VADER sentiment df for ESG-related news\n",
    "news_df.to_csv('../Data/Output/obj2_ESG_news_vader.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neut_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>Sent_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.010250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>-0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>-0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.135904</td>\n",
       "      <td>0.755808</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.025644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.138128</td>\n",
       "      <td>0.766626</td>\n",
       "      <td>0.095246</td>\n",
       "      <td>0.040455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.754064</td>\n",
       "      <td>0.078770</td>\n",
       "      <td>0.064284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>0.154341</td>\n",
       "      <td>0.733763</td>\n",
       "      <td>0.111896</td>\n",
       "      <td>0.035742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.147199</td>\n",
       "      <td>0.729597</td>\n",
       "      <td>0.123203</td>\n",
       "      <td>0.022322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company        date  pos_prob  neut_prob  neg_prob    Sent_d\n",
       "0      Asda  2024-06-07  0.138000   0.765000  0.097000  0.010250\n",
       "1      Asda  2024-07-08  0.173000   0.818000  0.009000  0.065600\n",
       "2      Asda  2024-07-23  0.097000   0.624000  0.279000 -0.045500\n",
       "3      Asda  2024-07-24  0.163000   0.794000  0.043000  0.048000\n",
       "4      Asda  2024-07-26  0.097000   0.608000  0.295000 -0.049500\n",
       "..      ...         ...       ...        ...       ...       ...\n",
       "211  Toyota  2024-07-25  0.135904   0.755808  0.108288  0.025644\n",
       "212  Toyota  2024-07-26  0.138128   0.766626  0.095246  0.040455\n",
       "213  Toyota  2024-07-27  0.167167   0.754064  0.078770  0.064284\n",
       "214  Toyota  2024-07-28  0.154341   0.733763  0.111896  0.035742\n",
       "215  Toyota  2024-07-29  0.147199   0.729597  0.123203  0.022322\n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to normalise sentiment proportions and calculate Sent_d\n",
    "def calculate_sentiment_score(df):\n",
    "    # Calculate total count of all sentiment categories\n",
    "    df['total'] = df['pos'] + df['neu'] + df['neg']\n",
    "    \n",
    "    # Normalize to get probabilities (frequencies) of positive, neutral, and negative\n",
    "    df['pos_prob'] = df['pos'] / df['total']\n",
    "    df['neut_prob'] = df['neu'] / df['total']\n",
    "    df['neg_prob'] = df['neg'] / df['total']\n",
    "    \n",
    "    # Confirm the probabilities sum to 1\n",
    "    df['sum_probs'] = df['pos_prob'] + df['neut_prob'] + df['neg_prob']\n",
    "    \n",
    "    # Calculate Sent_d using the normalized probabilities\n",
    "    df['Sent_d'] = (df['pos'] - df['neg']) / (df['pos'] + df['neu'] + df['neg'] + 3)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Group by company and date for daily aggregation\n",
    "grouped_df = news_df.groupby(['company', 'date']).sum().reset_index()\n",
    "\n",
    "# Apply the sentiment calculation\n",
    "Daily_Sentiment_Compound_df = calculate_sentiment_score(grouped_df)\n",
    "\n",
    "\n",
    "Daily_Sentiment_Compound_df = Daily_Sentiment_Compound_df[['company', 'date', 'pos_prob', 'neut_prob', 'neg_prob', 'Sent_d']]\n",
    "\n",
    "Daily_Sentiment_Compound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save Daily_Sentiment_Compound_df for ESG-related news\n",
    "\n",
    "Daily_Sentiment_Compound_df.to_csv('../Data/Output/obj2_ESG_daily_sentiment_compound.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's perform the Granger’s causality testing using the dedicated Python library “grangercausalitytests.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'date' column is in datetime format in both dataframes\n",
    "Daily_Sentiment_Compound_df['date'] = pd.to_datetime(Daily_Sentiment_Compound_df['date'])\n",
    "stock_performance_df['date'] = pd.to_datetime(stock_performance_df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the sentiment dataframe with the stock performance dataframe on 'company' and 'date'\n",
    "merged_df = pd.merge(Daily_Sentiment_Compound_df[['company', 'date', 'Sent_d']], \n",
    "                     stock_performance_df[['company', 'date', 'daily_return']], \n",
    "                     on=['company', 'date'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.045500</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.049500</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.034458</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>-0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "0      Asda 2024-06-07  0.010250     -0.019094\n",
       "1      Asda 2024-07-08  0.065600     -0.005153\n",
       "2      Asda 2024-07-23 -0.045500      0.003829\n",
       "3      Asda 2024-07-24  0.048000     -0.000708\n",
       "4      Asda 2024-07-26 -0.049500     -0.003433\n",
       "..      ...        ...       ...           ...\n",
       "177  Toyota 2024-07-23  0.034458      0.003242\n",
       "178  Toyota 2024-07-24  0.019665     -0.018041\n",
       "179  Toyota 2024-07-25  0.025644     -0.009938\n",
       "180  Toyota 2024-07-26  0.040455     -0.014081\n",
       "181  Toyota 2024-07-29  0.022322     -0.000208\n",
       "\n",
       "[182 rows x 4 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.045500</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.049500</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.034458</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>-0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "0      Asda 2024-06-07  0.010250     -0.019094\n",
       "1      Asda 2024-07-08  0.065600     -0.005153\n",
       "2      Asda 2024-07-23 -0.045500      0.003829\n",
       "3      Asda 2024-07-24  0.048000     -0.000708\n",
       "4      Asda 2024-07-26 -0.049500     -0.003433\n",
       "..      ...        ...       ...           ...\n",
       "177  Toyota 2024-07-23  0.034458      0.003242\n",
       "178  Toyota 2024-07-24  0.019665     -0.018041\n",
       "179  Toyota 2024-07-25  0.025644     -0.009938\n",
       "180  Toyota 2024-07-26  0.040455     -0.014081\n",
       "181  Toyota 2024-07-29  0.022322     -0.000208\n",
       "\n",
       "[181 rows x 4 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any rows with missing data, as Granger causality tests require complete cases\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged_df\n",
    "merged_df.to_csv('../Data/Output/obj2_ESGnews_stock_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.01025</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.06560</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.04550</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.04800</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.04950</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company       date   Sent_d  daily_return\n",
       "0    Asda 2024-06-07  0.01025     -0.019094\n",
       "1    Asda 2024-07-08  0.06560     -0.005153\n",
       "2    Asda 2024-07-23 -0.04550      0.003829\n",
       "3    Asda 2024-07-24  0.04800     -0.000708\n",
       "4    Asda 2024-07-26 -0.04950     -0.003433"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Asda'\n",
    "Asda_merged_df = merged_df[merged_df['company'] == 'Asda']\n",
    "Asda_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.2503  , p=0.7047  , df_denom=1, df_num=1\n",
      "ssr based chi2 test:   chi2=1.0011  , p=0.3171  , df=1\n",
      "likelihood ratio test: chi2=0.8934  , p=0.3445  , df=1\n",
      "parameter F test:         F=0.2503  , p=0.7047  , df_denom=1, df_num=1\n",
      "Lag 1: p-value = 0.7046968509482529\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for ASDA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Asda_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>0.064774</td>\n",
       "      <td>0.023492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>0.033250</td>\n",
       "      <td>0.013491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>-0.008410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>0.059420</td>\n",
       "      <td>0.032408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>0.059571</td>\n",
       "      <td>-0.011513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company       date    Sent_d  daily_return\n",
       "5    Ford 2024-05-02  0.064774      0.023492\n",
       "6    Ford 2024-06-20  0.033250      0.013491\n",
       "7    Ford 2024-06-21  0.059697     -0.008410\n",
       "8    Ford 2024-06-24  0.059420      0.032408\n",
       "9    Ford 2024-06-25  0.059571     -0.011513"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Ford'\n",
    "Ford_merged_df = merged_df[merged_df['company'] == 'Ford']\n",
    "Ford_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.2008  , p=0.2869  , df_denom=19, df_num=1\n",
      "ssr based chi2 test:   chi2=1.3904  , p=0.2383  , df=1\n",
      "likelihood ratio test: chi2=1.3482  , p=0.2456  , df=1\n",
      "parameter F test:         F=1.2008  , p=0.2869  , df_denom=19, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.0739  , p=0.3651  , df_denom=16, df_num=2\n",
      "ssr based chi2 test:   chi2=2.8189  , p=0.2443  , df=2\n",
      "likelihood ratio test: chi2=2.6451  , p=0.2665  , df=2\n",
      "parameter F test:         F=1.0739  , p=0.3651  , df_denom=16, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.4889  , p=0.6960  , df_denom=13, df_num=3\n",
      "ssr based chi2 test:   chi2=2.2562  , p=0.5210  , df=3\n",
      "likelihood ratio test: chi2=2.1378  , p=0.5443  , df=3\n",
      "parameter F test:         F=0.4889  , p=0.6960  , df_denom=13, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.7570  , p=0.5761  , df_denom=10, df_num=4\n",
      "ssr based chi2 test:   chi2=5.7532  , p=0.2184  , df=4\n",
      "likelihood ratio test: chi2=5.0258  , p=0.2847  , df=4\n",
      "parameter F test:         F=0.7570  , p=0.5761  , df_denom=10, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.7338  , p=0.6209  , df_denom=7, df_num=5\n",
      "ssr based chi2 test:   chi2=9.4344  , p=0.0929  , df=5\n",
      "likelihood ratio test: chi2=7.5856  , p=0.1806  , df=5\n",
      "parameter F test:         F=0.7338  , p=0.6209  , df_denom=7, df_num=5\n",
      "Lag 1: p-value = 0.2868602307196189\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.36506838249549345\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.6959776073748872\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.576089166662729\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.620929205025862\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for FORD\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Ford_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>0.050563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>0.055667</td>\n",
       "      <td>0.013485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.003230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            company       date    Sent_d  daily_return\n",
       "28  Marks & Spencer 2024-05-22  0.062016      0.050563\n",
       "29  Marks & Spencer 2024-05-29  0.047012      0.002646\n",
       "30  Marks & Spencer 2024-05-30  0.042200      0.003626\n",
       "31  Marks & Spencer 2024-06-03  0.055667      0.013485\n",
       "32  Marks & Spencer 2024-06-06  0.037000      0.003230"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Marks & Spencer'\n",
    "MarksSpencer_merged_df = merged_df[merged_df['company'] == 'Marks & Spencer']\n",
    "MarksSpencer_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=6.3092  , p=0.0203  , df_denom=21, df_num=1\n",
      "ssr based chi2 test:   chi2=7.2105  , p=0.0072  , df=1\n",
      "likelihood ratio test: chi2=6.3048  , p=0.0120  , df=1\n",
      "parameter F test:         F=6.3092  , p=0.0203  , df_denom=21, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=7.8530  , p=0.0035  , df_denom=18, df_num=2\n",
      "ssr based chi2 test:   chi2=20.0688 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=14.4280 , p=0.0007  , df=2\n",
      "parameter F test:         F=7.8530  , p=0.0035  , df_denom=18, df_num=2\n",
      "Lag 1: p-value = 0.020254700175103175\n",
      "At lag 1, we reject the null hypothesis. Sentiment influences stock market performance.\n",
      "\n",
      "Lag 2: p-value = 0.0035325440251965604\n",
      "At lag 2, we reject the null hypothesis. Sentiment influences stock market performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for M&S\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 2\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(MarksSpencer_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.022582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.052527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>0.074819</td>\n",
       "      <td>0.057371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>-0.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.037378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company       date    Sent_d  daily_return\n",
       "53   Ocado 2024-05-09  0.037000      0.022582\n",
       "54   Ocado 2024-07-08  0.002250      0.052527\n",
       "55   Ocado 2024-07-16  0.074819      0.057371\n",
       "56   Ocado 2024-07-17  0.063500     -0.008357\n",
       "57   Ocado 2024-07-19 -0.002001     -0.037378"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Ocado'\n",
    "Ocado_merged_df = merged_df[merged_df['company'] == 'Ocado']\n",
    "Ocado_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=2.7205  , p=0.1600  , df_denom=5, df_num=1\n",
      "ssr based chi2 test:   chi2=4.3527  , p=0.0369  , df=1\n",
      "likelihood ratio test: chi2=3.4755  , p=0.0623  , df=1\n",
      "parameter F test:         F=2.7205  , p=0.1600  , df_denom=5, df_num=1\n",
      "Lag 1: p-value = 0.1599826891583226\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for OCADO\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Ocado_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.025477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>-0.007145</td>\n",
       "      <td>-0.048391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company       date    Sent_d  daily_return\n",
       "62  Polestar 2024-06-05  0.028571      0.025477\n",
       "63  Polestar 2024-06-28 -0.007145     -0.048391"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Polestar'\n",
    "Polestar_merged_df = merged_df[merged_df['company'] == 'Polestar']\n",
    "Polestar_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient observations. Maximum allowable lag is -1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m max_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m granger_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrangercausalitytests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPolestar_merged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSent_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print summary of the test results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag, test_result \u001b[38;5;129;01min\u001b[39;00m granger_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1567\u001b[0m, in \u001b[0;36mgrangercausalitytests\u001b[0;34m(x, maxlag, addconst, verbose)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag must be a non-empty list containing only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive integers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1564\u001b[0m         )\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst):\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient observations. Maximum allowable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1570\u001b[0m     )\n\u001b[1;32m   1572\u001b[0m resli \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mlg \u001b[38;5;129;01min\u001b[39;00m lags:\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient observations. Maximum allowable lag is -1"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for POLESTAR\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Polestar_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>-0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.010921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>-0.00680</td>\n",
       "      <td>-0.029124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.018962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date   Sent_d  daily_return\n",
       "64  Sainsburys 2024-06-12  0.04050     -0.002337\n",
       "65  Sainsburys 2024-07-01  0.09350      0.010921\n",
       "66  Sainsburys 2024-07-02 -0.00680     -0.029124\n",
       "67  Sainsburys 2024-07-16  0.04375      0.018962"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Sainsburys'\n",
    "Sainsburys_merged_df = merged_df[merged_df['company'] == 'Sainsburys']\n",
    "Sainsburys_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient observations. Maximum allowable lag is 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m max_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m granger_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrangercausalitytests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSainsburys_merged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSent_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print summary of the test results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag, test_result \u001b[38;5;129;01min\u001b[39;00m granger_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1567\u001b[0m, in \u001b[0;36mgrangercausalitytests\u001b[0;34m(x, maxlag, addconst, verbose)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag must be a non-empty list containing only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive integers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1564\u001b[0m         )\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst):\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient observations. Maximum allowable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1570\u001b[0m     )\n\u001b[1;32m   1572\u001b[0m resli \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mlg \u001b[38;5;129;01min\u001b[39;00m lags:\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient observations. Maximum allowable lag is 0"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for SAINSBURY'S\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Sainsburys_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>0.017366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>-0.017500</td>\n",
       "      <td>-0.004931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>0.033807</td>\n",
       "      <td>-0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.036315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.020707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date    Sent_d  daily_return\n",
       "68  Stellantis 2024-05-03  0.023250      0.017366\n",
       "69  Stellantis 2024-05-06 -0.017500     -0.004931\n",
       "70  Stellantis 2024-05-07  0.033807     -0.001484\n",
       "71  Stellantis 2024-05-13  0.004750      0.036315\n",
       "72  Stellantis 2024-05-14  0.080800      0.020707"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Stellantis'\n",
    "Stellantis_merged_df = merged_df[merged_df['company'] == 'Stellantis']\n",
    "Stellantis_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.0633  , p=0.8053  , df_denom=13, df_num=1\n",
      "ssr based chi2 test:   chi2=0.0779  , p=0.7801  , df=1\n",
      "likelihood ratio test: chi2=0.0777  , p=0.7804  , df=1\n",
      "parameter F test:         F=0.0633  , p=0.8053  , df_denom=13, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.0408  , p=0.9602  , df_denom=10, df_num=2\n",
      "ssr based chi2 test:   chi2=0.1223  , p=0.9407  , df=2\n",
      "likelihood ratio test: chi2=0.1218  , p=0.9409  , df=2\n",
      "parameter F test:         F=0.0408  , p=0.9602  , df_denom=10, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.0452  , p=0.9862  , df_denom=7, df_num=3\n",
      "ssr based chi2 test:   chi2=0.2711  , p=0.9654  , df=3\n",
      "likelihood ratio test: chi2=0.2685  , p=0.9658  , df=3\n",
      "parameter F test:         F=0.0452  , p=0.9862  , df_denom=7, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.1878  , p=0.9329  , df_denom=4, df_num=4\n",
      "ssr based chi2 test:   chi2=2.4411  , p=0.6552  , df=4\n",
      "likelihood ratio test: chi2=2.2371  , p=0.6923  , df=4\n",
      "parameter F test:         F=0.1878  , p=0.9329  , df_denom=4, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.3665  , p=0.8405  , df_denom=1, df_num=5\n",
      "ssr based chi2 test:   chi2=21.9901 , p=0.0005  , df=5\n",
      "likelihood ratio test: chi2=12.4940 , p=0.0286  , df=5\n",
      "parameter F test:         F=0.3665  , p=0.8405  , df_denom=1, df_num=5\n",
      "Lag 1: p-value = 0.8052539771426362\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.960207926306211\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.986174827293431\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.9329252430394402\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.8405180410406692\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for STELLANTIS\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Stellantis_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>-0.005016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.007767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>-0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.001610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company       date    Sent_d  daily_return\n",
       "85   Tesco 2024-05-03  0.049500     -0.005016\n",
       "86   Tesco 2024-05-09 -0.011000      0.007767\n",
       "87   Tesco 2024-05-14  0.064857      0.004150\n",
       "88   Tesco 2024-05-15  0.024010     -0.010247\n",
       "89   Tesco 2024-05-20  0.001000     -0.001610"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Tesco'\n",
    "Tesco_merged_df = merged_df[merged_df['company'] == 'Tesco']\n",
    "Tesco_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.2004  , p=0.6581  , df_denom=26, df_num=1\n",
      "ssr based chi2 test:   chi2=0.2236  , p=0.6363  , df=1\n",
      "likelihood ratio test: chi2=0.2227  , p=0.6370  , df=1\n",
      "parameter F test:         F=0.2004  , p=0.6581  , df_denom=26, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.5867  , p=0.5643  , df_denom=23, df_num=2\n",
      "ssr based chi2 test:   chi2=1.4285  , p=0.4896  , df=2\n",
      "likelihood ratio test: chi2=1.3933  , p=0.4983  , df=2\n",
      "parameter F test:         F=0.5867  , p=0.5643  , df_denom=23, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.3581  , p=0.7838  , df_denom=20, df_num=3\n",
      "ssr based chi2 test:   chi2=1.4504  , p=0.6938  , df=3\n",
      "likelihood ratio test: chi2=1.4127  , p=0.7026  , df=3\n",
      "parameter F test:         F=0.3581  , p=0.7838  , df_denom=20, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.1728  , p=0.9493  , df_denom=17, df_num=4\n",
      "ssr based chi2 test:   chi2=1.0570  , p=0.9010  , df=4\n",
      "likelihood ratio test: chi2=1.0361  , p=0.9043  , df=4\n",
      "parameter F test:         F=0.1728  , p=0.9493  , df_denom=17, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.1148  , p=0.9870  , df_denom=14, df_num=5\n",
      "ssr based chi2 test:   chi2=1.0254  , p=0.9605  , df=5\n",
      "likelihood ratio test: chi2=1.0049  , p=0.9622  , df=5\n",
      "parameter F test:         F=0.1148  , p=0.9870  , df_denom=14, df_num=5\n",
      "Lag 1: p-value = 0.6580722251234585\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.5642583323185102\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.783839758167563\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.9493322523916833\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.9870422130991938\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TESCO\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Tesco_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>-0.017531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>-0.020562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>-0.013748</td>\n",
       "      <td>0.014874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>-0.014245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "115   Tesla 2024-05-08  0.001750     -0.017531\n",
       "116   Tesla 2024-05-10  0.003834     -0.020562\n",
       "117   Tesla 2024-05-14 -0.002999      0.032398\n",
       "118   Tesla 2024-05-17 -0.013748      0.014874\n",
       "119   Tesla 2024-05-20  0.092000     -0.014245"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Tesla'\n",
    "Tesla_merged_df = merged_df[merged_df['company'] == 'Tesla']\n",
    "Tesla_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.2243  , p=0.6390  , df_denom=32, df_num=1\n",
      "ssr based chi2 test:   chi2=0.2453  , p=0.6204  , df=1\n",
      "likelihood ratio test: chi2=0.2445  , p=0.6210  , df=1\n",
      "parameter F test:         F=0.2243  , p=0.6390  , df_denom=32, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.6719  , p=0.0861  , df_denom=29, df_num=2\n",
      "ssr based chi2 test:   chi2=6.2650  , p=0.0436  , df=2\n",
      "likelihood ratio test: chi2=5.7502  , p=0.0564  , df=2\n",
      "parameter F test:         F=2.6719  , p=0.0861  , df_denom=29, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.8542  , p=0.0209  , df_denom=26, df_num=3\n",
      "ssr based chi2 test:   chi2=14.6756 , p=0.0021  , df=3\n",
      "likelihood ratio test: chi2=12.1411 , p=0.0069  , df=3\n",
      "parameter F test:         F=3.8542  , p=0.0209  , df_denom=26, df_num=3\n",
      "Lag 1: p-value = 0.63900636811279\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.08609643318819739\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.020899595202116105\n",
      "At lag 3, we reject the null hypothesis. Sentiment influences stock market performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TESLA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 3\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Tesla_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>0.011130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>0.042604</td>\n",
       "      <td>0.008633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>-0.022050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "152  Toyota 2024-05-02  0.104901      0.017351\n",
       "153  Toyota 2024-05-14  0.089400      0.006840\n",
       "154  Toyota 2024-05-15  0.048750      0.011130\n",
       "155  Toyota 2024-05-28  0.042604      0.008633\n",
       "156  Toyota 2024-05-29  0.075500     -0.022050"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Toyota'\n",
    "Toyota_merged_df = merged_df[merged_df['company'] == 'Toyota']\n",
    "Toyota_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.3807  , p=0.5426  , df_denom=26, df_num=1\n",
      "ssr based chi2 test:   chi2=0.4246  , p=0.5146  , df=1\n",
      "likelihood ratio test: chi2=0.4216  , p=0.5162  , df=1\n",
      "parameter F test:         F=0.3807  , p=0.5426  , df_denom=26, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.1237  , p=0.8842  , df_denom=23, df_num=2\n",
      "ssr based chi2 test:   chi2=0.3012  , p=0.8602  , df=2\n",
      "likelihood ratio test: chi2=0.2996  , p=0.8609  , df=2\n",
      "parameter F test:         F=0.1237  , p=0.8842  , df_denom=23, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.6975  , p=0.5645  , df_denom=20, df_num=3\n",
      "ssr based chi2 test:   chi2=2.8250  , p=0.4194  , df=3\n",
      "likelihood ratio test: chi2=2.6867  , p=0.4425  , df=3\n",
      "parameter F test:         F=0.6975  , p=0.5645  , df_denom=20, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.8584  , p=0.5084  , df_denom=17, df_num=4\n",
      "ssr based chi2 test:   chi2=5.2511  , p=0.2625  , df=4\n",
      "likelihood ratio test: chi2=4.7829  , p=0.3103  , df=4\n",
      "parameter F test:         F=0.8584  , p=0.5084  , df_denom=17, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.1088  , p=0.3992  , df_denom=14, df_num=5\n",
      "ssr based chi2 test:   chi2=9.9004  , p=0.0781  , df=5\n",
      "likelihood ratio test: chi2=8.3406  , p=0.1384  , df=5\n",
      "parameter F test:         F=1.1088  , p=0.3992  , df_denom=14, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.2651  , p=0.3473  , df_denom=11, df_num=6\n",
      "ssr based chi2 test:   chi2=16.5617 , p=0.0110  , df=6\n",
      "likelihood ratio test: chi2=12.5945 , p=0.0499  , df=6\n",
      "parameter F test:         F=1.2651  , p=0.3473  , df_denom=11, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.8468  , p=0.5803  , df_denom=8, df_num=7\n",
      "ssr based chi2 test:   chi2=17.0411 , p=0.0171  , df=7\n",
      "likelihood ratio test: chi2=12.7515 , p=0.0784  , df=7\n",
      "parameter F test:         F=0.8468  , p=0.5803  , df_denom=8, df_num=7\n",
      "Lag 1: p-value = 0.5425880342272407\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.8842182841864764\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.56445272192797\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.5084054209548492\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.39922360328376316\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 6: p-value = 0.34730862825513387\n",
      "At lag 6, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 7: p-value = 0.5803384105494689\n",
      "At lag 7, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TOYOTA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 7\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Toyota_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  total_days  available_data_points  percentage_available\n",
      "0             Asda          92                      5              5.434783\n",
      "1             Ford          92                     23             25.000000\n",
      "2  Marks & Spencer          92                     25             27.173913\n",
      "3            Ocado          92                      9              9.782609\n",
      "4         Polestar          92                      2              2.173913\n",
      "5       Sainsburys          92                      4              4.347826\n",
      "6       Stellantis          92                     17             18.478261\n",
      "7            Tesco          92                     30             32.608696\n",
      "8            Tesla          92                     36             39.130435\n",
      "9           Toyota          92                     30             32.608696\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "# Count the number of available data points per company\n",
    "available_data_counts = merged_df.groupby('company').size().reset_index(name='available_data_points')\n",
    "\n",
    "# Add the total_days column with the same value for all companies\n",
    "available_data_counts['total_days'] = N\n",
    "\n",
    "# Calculate the percentage of available data\n",
    "available_data_counts['percentage_available'] = (available_data_counts['available_data_points'] / available_data_counts['total_days']) * 100\n",
    "\n",
    "# Display the result\n",
    "print(available_data_counts[['company', 'total_days', 'available_data_points', 'percentage_available']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: M&S and Tesla show correlation between sentiment and returns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myprojenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
