{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict stock market volatility using ESG-related news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/luca/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/luca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/luca/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/luca/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "\n",
    "# Granger's casuality test library\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "# Import VADER for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate the daily market returns time series and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.380</td>\n",
       "      <td>13.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>13.28</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.370</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-03</td>\n",
       "      <td>13.65</td>\n",
       "      <td>13.25</td>\n",
       "      <td>13.680</td>\n",
       "      <td>13.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>13.21</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13.950</td>\n",
       "      <td>13.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>13.28</td>\n",
       "      <td>13.27</td>\n",
       "      <td>13.395</td>\n",
       "      <td>13.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>330.50</td>\n",
       "      <td>328.50</td>\n",
       "      <td>331.100</td>\n",
       "      <td>326.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>333.50</td>\n",
       "      <td>331.70</td>\n",
       "      <td>333.900</td>\n",
       "      <td>330.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>335.00</td>\n",
       "      <td>333.80</td>\n",
       "      <td>338.000</td>\n",
       "      <td>333.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-14</td>\n",
       "      <td>340.60</td>\n",
       "      <td>336.50</td>\n",
       "      <td>340.600</td>\n",
       "      <td>336.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>341.20</td>\n",
       "      <td>341.50</td>\n",
       "      <td>342.000</td>\n",
       "      <td>338.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company  symbol        date   close    open     high      low\n",
       "0      Ford       F  2024-04-01   13.29   13.33   13.380   13.140\n",
       "1      Ford       F  2024-04-02   13.28   13.16   13.370   13.090\n",
       "2      Ford       F  2024-04-03   13.65   13.25   13.680   13.230\n",
       "3      Ford       F  2024-04-04   13.21   13.90   13.950   13.170\n",
       "4      Ford       F  2024-04-05   13.28   13.27   13.395   13.090\n",
       "..      ...     ...         ...     ...     ...      ...      ...\n",
       "955   Tesco  TSCO.L  2024-08-09  330.50  328.50  331.100  326.200\n",
       "956   Tesco  TSCO.L  2024-08-12  333.50  331.70  333.900  330.880\n",
       "957   Tesco  TSCO.L  2024-08-13  335.00  333.80  338.000  333.400\n",
       "958   Tesco  TSCO.L  2024-08-14  340.60  336.50  340.600  336.400\n",
       "959   Tesco  TSCO.L  2024-08-15  341.20  341.50  342.000  338.596\n",
       "\n",
       "[960 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load price data\n",
    "prices_file_path = '../Data/Input/Eikon/refinitiv_prices_raw.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "prices_df = pd.read_csv(prices_file_path)\n",
    "\n",
    "prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "   company symbol       date  close   open   high      low\n",
      "22    Ford      F 2024-05-01  12.20  12.16  12.43  12.1500\n",
      "23    Ford      F 2024-05-02  12.49  12.40  12.55  12.3600\n",
      "24    Ford      F 2024-05-03  12.43  12.64  12.76  12.3900\n",
      "25    Ford      F 2024-05-06  12.50  12.54  12.62  12.4575\n",
      "26    Ford      F 2024-05-07  12.17  12.40  12.45  12.0850\n"
     ]
    }
   ],
   "source": [
    "# Let's filter the dataset to match the dates of the available news stories \n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "\n",
    "# Define the date range for filtering\n",
    "start_date = '2024-05-01'\n",
    "end_date = '2024-07-31'\n",
    "\n",
    "# Convert string to datetime object\n",
    "date_format = \"%Y-%m-%d\"\n",
    "start_date = datetime.strptime(start_date, date_format)\n",
    "end_date = datetime.strptime(end_date, date_format)\n",
    "\n",
    "delta = (end_date-start_date)\n",
    "N = delta.days + 1\n",
    "print(N)\n",
    "\n",
    "# Filter the DataFrame to keep rows between 1st May 2024 and 31st July 2024\n",
    "stock_performance_df = prices_df[(prices_df['date'] >= start_date) & (prices_df['date'] <= end_date)]\n",
    "\n",
    "# Display the filtered data\n",
    "print(stock_performance_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.16</td>\n",
       "      <td>12.4300</td>\n",
       "      <td>12.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>12.49</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.5500</td>\n",
       "      <td>12.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>12.43</td>\n",
       "      <td>12.64</td>\n",
       "      <td>12.7600</td>\n",
       "      <td>12.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12.6200</td>\n",
       "      <td>12.4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ford</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>12.17</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.4500</td>\n",
       "      <td>12.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>325.60</td>\n",
       "      <td>325.60</td>\n",
       "      <td>327.1000</td>\n",
       "      <td>323.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>327.10</td>\n",
       "      <td>325.10</td>\n",
       "      <td>328.6000</td>\n",
       "      <td>323.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>330.90</td>\n",
       "      <td>330.00</td>\n",
       "      <td>333.7000</td>\n",
       "      <td>328.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>331.70</td>\n",
       "      <td>330.00</td>\n",
       "      <td>332.8000</td>\n",
       "      <td>328.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>TSCO.L</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>331.60</td>\n",
       "      <td>331.90</td>\n",
       "      <td>334.2996</td>\n",
       "      <td>330.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company  symbol       date   close    open      high       low\n",
       "22     Ford       F 2024-05-01   12.20   12.16   12.4300   12.1500\n",
       "23     Ford       F 2024-05-02   12.49   12.40   12.5500   12.3600\n",
       "24     Ford       F 2024-05-03   12.43   12.64   12.7600   12.3900\n",
       "25     Ford       F 2024-05-06   12.50   12.54   12.6200   12.4575\n",
       "26     Ford       F 2024-05-07   12.17   12.40   12.4500   12.0850\n",
       "..      ...     ...        ...     ...     ...       ...       ...\n",
       "944   Tesco  TSCO.L 2024-07-25  325.60  325.60  327.1000  323.4000\n",
       "945   Tesco  TSCO.L 2024-07-26  327.10  325.10  328.6000  323.3490\n",
       "946   Tesco  TSCO.L 2024-07-29  330.90  330.00  333.7000  328.1630\n",
       "947   Tesco  TSCO.L 2024-07-30  331.70  330.00  332.8000  328.4000\n",
       "948   Tesco  TSCO.L 2024-07-31  331.60  331.90  334.2996  330.5000\n",
       "\n",
       "[636 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily market return on day t is calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "r_{t} = ln \\left(\\frac{CLOSE_{t}}{CLOSE_{t-1}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $CLOSE_{t}$ is the closing price on day t and $CLOSE_{t-1}$ is the previous day closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by company and date to maintain the proper order for each company\n",
    "stock_performance_df = stock_performance_df.sort_values(by=['company', 'date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    company symbol       date  close   open    high    low  daily_return\n",
      "502    Asda    WMT 2024-05-01  58.85  59.31  59.410  58.72           NaN\n",
      "503    Asda    WMT 2024-05-02  59.71  58.94  59.885  58.58      0.014508\n",
      "504    Asda    WMT 2024-05-03  59.82  59.62  59.980  59.14      0.001841\n",
      "505    Asda    WMT 2024-05-06  59.87  60.00  60.000  59.39      0.000835\n",
      "506    Asda    WMT 2024-05-07  60.62  60.17  60.800  60.05      0.012449\n"
     ]
    }
   ],
   "source": [
    "# Calculate daily market return using the formula: r_t = log(CLOSE_t / CLOSE_t-1)\n",
    "stock_performance_df['daily_return'] = stock_performance_df.groupby('company', group_keys=False)['close'].apply(\n",
    "    lambda x: np.log(x / x.shift(1))\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(stock_performance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>58.85</td>\n",
       "      <td>59.31</td>\n",
       "      <td>59.410</td>\n",
       "      <td>58.7200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>59.71</td>\n",
       "      <td>58.94</td>\n",
       "      <td>59.885</td>\n",
       "      <td>58.5800</td>\n",
       "      <td>0.014508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>59.82</td>\n",
       "      <td>59.62</td>\n",
       "      <td>59.980</td>\n",
       "      <td>59.1400</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>59.87</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.000</td>\n",
       "      <td>59.3900</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Asda</td>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>60.62</td>\n",
       "      <td>60.17</td>\n",
       "      <td>60.800</td>\n",
       "      <td>60.0500</td>\n",
       "      <td>0.012449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>195.25</td>\n",
       "      <td>197.43</td>\n",
       "      <td>197.430</td>\n",
       "      <td>193.7300</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>192.52</td>\n",
       "      <td>190.74</td>\n",
       "      <td>192.840</td>\n",
       "      <td>190.5100</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>192.48</td>\n",
       "      <td>193.00</td>\n",
       "      <td>193.200</td>\n",
       "      <td>191.8067</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>193.11</td>\n",
       "      <td>194.96</td>\n",
       "      <td>195.480</td>\n",
       "      <td>192.2650</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>TM</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>193.55</td>\n",
       "      <td>194.18</td>\n",
       "      <td>194.890</td>\n",
       "      <td>192.9000</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company symbol       date   close    open     high       low  daily_return\n",
       "502    Asda    WMT 2024-05-01   58.85   59.31   59.410   58.7200           NaN\n",
       "503    Asda    WMT 2024-05-02   59.71   58.94   59.885   58.5800      0.014508\n",
       "504    Asda    WMT 2024-05-03   59.82   59.62   59.980   59.1400      0.001841\n",
       "505    Asda    WMT 2024-05-06   59.87   60.00   60.000   59.3900      0.000835\n",
       "506    Asda    WMT 2024-05-07   60.62   60.17   60.800   60.0500      0.012449\n",
       "..      ...    ...        ...     ...     ...      ...       ...           ...\n",
       "464  Toyota     TM 2024-07-25  195.25  197.43  197.430  193.7300     -0.009938\n",
       "465  Toyota     TM 2024-07-26  192.52  190.74  192.840  190.5100     -0.014081\n",
       "466  Toyota     TM 2024-07-29  192.48  193.00  193.200  191.8067     -0.000208\n",
       "467  Toyota     TM 2024-07-30  193.11  194.96  195.480  192.2650      0.003268\n",
       "468  Toyota     TM 2024-07-31  193.55  194.18  194.890  192.9000      0.002276\n",
       "\n",
       "[636 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Volatility\n",
    "\n",
    "The volatility of the stock market index is calculated within a defined time window (e.g., previous 90 days):\n",
    "\n",
    "\\begin{equation}\n",
    "Vol = \\sqrt{\\frac{1}{N}\\sum_{t=1}^{N}(r_{t}-\\bar{r})^2} \\cdot \\sqrt{252}\n",
    "\\end{equation}\n",
    "\n",
    "where N is the total number of days during a window time of observations (eg, 30 days), and 252 is the total number of trading days in a single year;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  volatility\n",
      "0             Asda    0.187419\n",
      "1             Ford    0.477228\n",
      "2  Marks & Spencer    0.250589\n",
      "3            Ocado    0.745336\n",
      "4         Polestar    1.047160\n",
      "5       Sainsburys    0.195476\n",
      "6       Stellantis    0.294795\n",
      "7            Tesco    0.120855\n",
      "8            Tesla    0.566548\n",
      "9           Toyota    0.224128\n"
     ]
    }
   ],
   "source": [
    "def calculate_volatility(df):\n",
    "    # Group by company to calculate volatility for each stock\n",
    "    volatility_df = df.groupby('company').apply(lambda x: calculate_stock_volatility(x))\n",
    "    \n",
    "    # Reset the index \n",
    "    volatility_df = volatility_df.reset_index(drop=True)\n",
    "    \n",
    "    return volatility_df\n",
    "\n",
    "def calculate_stock_volatility(stock_df):\n",
    "    # Number of trading days (rows)\n",
    "    N = len(stock_df)\n",
    "    \n",
    "    # Mean of daily returns (r̄)\n",
    "    mean_return = stock_df['daily_return'].mean()\n",
    "    \n",
    "    # Variance calculation: (r_t - r̄)^2\n",
    "    variance = np.sum((stock_df['daily_return'] - mean_return) ** 2) / N\n",
    "    \n",
    "    # Daily volatility: sqrt(variance)\n",
    "    daily_volatility = np.sqrt(variance)\n",
    "    \n",
    "    # Annual volatility: daily_volatility * sqrt(252)\n",
    "    annual_volatility = daily_volatility * np.sqrt(252)\n",
    "    \n",
    "    # Return the company and its calculated volatility\n",
    "    return pd.Series({'company': stock_df['company'].iloc[0], 'volatility': annual_volatility})\n",
    "\n",
    "\n",
    "# Assuming filtered_df is already loaded and contains 'company' and 'daily_return' columns\n",
    "volatility_results = calculate_volatility(stock_performance_df)\n",
    "\n",
    "# Display the calculated volatility for each company\n",
    "print(volatility_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>1.047160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>0.745336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>0.566548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford</td>\n",
       "      <td>0.477228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>0.294795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>0.250589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>0.224128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>0.195476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>0.187419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>0.120855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           company  volatility\n",
       "4         Polestar    1.047160\n",
       "3            Ocado    0.745336\n",
       "8            Tesla    0.566548\n",
       "1             Ford    0.477228\n",
       "6       Stellantis    0.294795\n",
       "2  Marks & Spencer    0.250589\n",
       "9           Toyota    0.224128\n",
       "5       Sainsburys    0.195476\n",
       "0             Asda    0.187419\n",
       "7            Tesco    0.120855"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by 'volatility' in descending order\n",
    "volatility_results = volatility_results.sort_values(by='volatility', ascending=False)\n",
    "volatility_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run sentiment Analysis of the ESG news stories using VADER and set up the daily sentiment score time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca  accesswire  july 29 2024  the ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny  accesswire  july 29 2024  br...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc is inves...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv\\nalaska energy...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july  29 2024  globe newswire  ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>tesco the uks largest supermarket chain has sp...</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>tesco has been accused of giving struggling wo...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>tesco boss ken murphy has seen his pay deal mo...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>tesco has apologised after a black publisher s...</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>tesco ireland the republic of ireland based su...</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story        date company  \\\n",
       "0    los angeles ca  accesswire  july 29 2024  the ...  2024-07-29    Ford   \n",
       "1    new york city ny  accesswire  july 29 2024  br...  2024-07-29    Ford   \n",
       "2    ford alert bragar eagel amp squire pc is inves...  2024-07-29    Ford   \n",
       "3    first atlantic nickel corp fanv\\nalaska energy...  2024-07-29    Ford   \n",
       "4    palm beach fla july  29 2024  globe newswire  ...  2024-07-29    Ford   \n",
       "..                                                 ...         ...     ...   \n",
       "985  tesco the uks largest supermarket chain has sp...  2024-05-15   Tesco   \n",
       "986  tesco has been accused of giving struggling wo...  2024-05-14   Tesco   \n",
       "987  tesco boss ken murphy has seen his pay deal mo...  2024-05-14   Tesco   \n",
       "988  tesco has apologised after a black publisher s...  2024-05-20   Tesco   \n",
       "989  tesco ireland the republic of ireland based su...  2024-05-03   Tesco   \n",
       "\n",
       "             ticker  \n",
       "0               esg  \n",
       "1               esg  \n",
       "2               esg  \n",
       "3               esg  \n",
       "4               esg  \n",
       "..              ...  \n",
       "985      governance  \n",
       "986      governance  \n",
       "987      governance  \n",
       "988  sustainability  \n",
       "989  sustainability  \n",
       "\n",
       "[990 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Pre-Processed ESG stories data from Objective One\n",
    "stories_file_path = '../Data/Output/news_df.csv'\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "news_df = pd.read_csv(stories_file_path)\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's initialise the 'stop words' function for English \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july 29 2024 schall ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july 29 2024 brons...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july 29 2024 globe newswire fin...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date company  \\\n",
       "0  los angeles ca accesswire july 29 2024 schall ...  2024-07-29    Ford   \n",
       "1  new york city ny accesswire july 29 2024 brons...  2024-07-29    Ford   \n",
       "2  ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3  first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4  palm beach fla july 29 2024 globe newswire fin...  2024-07-29    Ford   \n",
       "\n",
       "  ticker  \n",
       "0    esg  \n",
       "1    esg  \n",
       "2    esg  \n",
       "3    esg  \n",
       "4    esg  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove 'stop words' from the stories\n",
    "\n",
    "news_df['story'] = news_df['story'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop]))\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july 29 2024 schall ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july 29 2024 brons...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july 29 2024 globe newswire fin...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>tesco uks largest supermarket chain sparked co...</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>tesco accused giving struggling workers slap f...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>tesco boss ken murphy seen pay deal double alm...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>tesco apologised black publisher says racially...</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.8141</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>tesco ireland republic ireland based subsidiar...</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story        date company  \\\n",
       "0    los angeles ca accesswire july 29 2024 schall ...  2024-07-29    Ford   \n",
       "1    new york city ny accesswire july 29 2024 brons...  2024-07-29    Ford   \n",
       "2    ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3    first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4    palm beach fla july 29 2024 globe newswire fin...  2024-07-29    Ford   \n",
       "..                                                 ...         ...     ...   \n",
       "985  tesco uks largest supermarket chain sparked co...  2024-05-15   Tesco   \n",
       "986  tesco accused giving struggling workers slap f...  2024-05-14   Tesco   \n",
       "987  tesco boss ken murphy seen pay deal double alm...  2024-05-14   Tesco   \n",
       "988  tesco apologised black publisher says racially...  2024-05-20   Tesco   \n",
       "989  tesco ireland republic ireland based subsidiar...  2024-05-03   Tesco   \n",
       "\n",
       "             ticker    neg    neu    pos  compound sentiment  \n",
       "0               esg  0.100  0.779  0.121    0.5267  positive  \n",
       "1               esg  0.065  0.864  0.071   -0.1531  negative  \n",
       "2               esg  0.063  0.800  0.137    0.9442  positive  \n",
       "3               esg  0.033  0.818  0.149    0.9995  positive  \n",
       "4               esg  0.033  0.819  0.148    0.9994  positive  \n",
       "..              ...    ...    ...    ...       ...       ...  \n",
       "985      governance  0.123  0.696  0.181    0.9442  positive  \n",
       "986      governance  0.116  0.704  0.180    0.9863  positive  \n",
       "987      governance  0.057  0.747  0.196    0.9882  positive  \n",
       "988  sustainability  0.142  0.732  0.125   -0.8141  negative  \n",
       "989  sustainability  0.009  0.797  0.194    0.9943  positive  \n",
       "\n",
       "[990 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to apply VADER and get sentiment scores\n",
    "def apply_vader_sentiment(text):\n",
    "    # Get the sentiment scores from VADER\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply VADER sentiment analysis to the \"story\" column\n",
    "news_df['vader_sentiment'] = news_df['story'].apply(apply_vader_sentiment)\n",
    "\n",
    "# Split the sentiment scores into separate columns (optional)\n",
    "news_df = pd.concat([news_df.drop(['vader_sentiment'], axis=1), news_df['vader_sentiment'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# Define a function to classify sentiment based on the 'compound' score\n",
    "def classify_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the classify_sentiment function to create a new 'sentiment' column\n",
    "news_df['sentiment'] = news_df['compound'].apply(classify_sentiment)\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles ca accesswire july 29 2024 schall ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york city ny accesswire july 29 2024 brons...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ford alert bragar eagel amp squire pc investig...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first atlantic nickel corp fanv alaska energy ...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>palm beach fla july 29 2024 globe newswire fin...</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>Ford</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>tesco uks largest supermarket chain sparked co...</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>tesco accused giving struggling workers slap f...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>tesco boss ken murphy seen pay deal double alm...</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>governance</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>tesco apologised black publisher says racially...</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.8141</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>tesco ireland republic ireland based subsidiar...</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story        date company  \\\n",
       "0    los angeles ca accesswire july 29 2024 schall ...  2024-07-29    Ford   \n",
       "1    new york city ny accesswire july 29 2024 brons...  2024-07-29    Ford   \n",
       "2    ford alert bragar eagel amp squire pc investig...  2024-07-29    Ford   \n",
       "3    first atlantic nickel corp fanv alaska energy ...  2024-07-29    Ford   \n",
       "4    palm beach fla july 29 2024 globe newswire fin...  2024-07-29    Ford   \n",
       "..                                                 ...         ...     ...   \n",
       "985  tesco uks largest supermarket chain sparked co...  2024-05-15   Tesco   \n",
       "986  tesco accused giving struggling workers slap f...  2024-05-14   Tesco   \n",
       "987  tesco boss ken murphy seen pay deal double alm...  2024-05-14   Tesco   \n",
       "988  tesco apologised black publisher says racially...  2024-05-20   Tesco   \n",
       "989  tesco ireland republic ireland based subsidiar...  2024-05-03   Tesco   \n",
       "\n",
       "             ticker    neg    neu    pos  compound sentiment  \n",
       "0               esg  0.100  0.779  0.121    0.5267  positive  \n",
       "1               esg  0.065  0.864  0.071   -0.1531  negative  \n",
       "2               esg  0.063  0.800  0.137    0.9442  positive  \n",
       "3               esg  0.033  0.818  0.149    0.9995  positive  \n",
       "4               esg  0.033  0.819  0.148    0.9994  positive  \n",
       "..              ...    ...    ...    ...       ...       ...  \n",
       "985      governance  0.123  0.696  0.181    0.9442  positive  \n",
       "986      governance  0.116  0.704  0.180    0.9863  positive  \n",
       "987      governance  0.057  0.747  0.196    0.9882  positive  \n",
       "988  sustainability  0.142  0.732  0.125   -0.8141  negative  \n",
       "989  sustainability  0.009  0.797  0.194    0.9943  positive  \n",
       "\n",
       "[990 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neut_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>Sent_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>-0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.154845</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>0.045582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>-0.047750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.126452</td>\n",
       "      <td>0.774171</td>\n",
       "      <td>0.099377</td>\n",
       "      <td>0.025141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.128203</td>\n",
       "      <td>0.786056</td>\n",
       "      <td>0.085742</td>\n",
       "      <td>0.040057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>0.154125</td>\n",
       "      <td>0.768875</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.056091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>0.142884</td>\n",
       "      <td>0.749781</td>\n",
       "      <td>0.107335</td>\n",
       "      <td>0.029938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.137161</td>\n",
       "      <td>0.745200</td>\n",
       "      <td>0.117638</td>\n",
       "      <td>0.018161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company        date  pos_prob  neut_prob  neg_prob    Sent_d\n",
       "0      Asda  2024-06-07  0.135000   0.770000  0.095000  0.010000\n",
       "1      Asda  2024-07-08  0.139000   0.852000  0.009000  0.052000\n",
       "2      Asda  2024-07-23  0.093000   0.640000  0.267000 -0.043500\n",
       "3      Asda  2024-07-24  0.154845   0.804196  0.040959  0.045582\n",
       "4      Asda  2024-07-26  0.094000   0.621000  0.285000 -0.047750\n",
       "..      ...         ...       ...        ...       ...       ...\n",
       "211  Toyota  2024-07-25  0.126452   0.774171  0.099377  0.025141\n",
       "212  Toyota  2024-07-26  0.128203   0.786056  0.085742  0.040057\n",
       "213  Toyota  2024-07-27  0.154125   0.768875  0.077000  0.056091\n",
       "214  Toyota  2024-07-28  0.142884   0.749781  0.107335  0.029938\n",
       "215  Toyota  2024-07-29  0.137161   0.745200  0.117638  0.018161\n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to normalise sentiment proportions and calculate Sent_d\n",
    "def calculate_sentiment_score(df):\n",
    "    # Calculate total count of all sentiment categories\n",
    "    df['total'] = df['pos'] + df['neu'] + df['neg']\n",
    "    \n",
    "    # Normalize to get probabilities (frequencies) of positive, neutral, and negative\n",
    "    df['pos_prob'] = df['pos'] / df['total']\n",
    "    df['neut_prob'] = df['neu'] / df['total']\n",
    "    df['neg_prob'] = df['neg'] / df['total']\n",
    "    \n",
    "    # Confirm the probabilities sum to 1\n",
    "    df['sum_probs'] = df['pos_prob'] + df['neut_prob'] + df['neg_prob']\n",
    "    \n",
    "    # Calculate Sent_d using the normalized probabilities\n",
    "    df['Sent_d'] = (df['pos'] - df['neg']) / (df['pos'] + df['neu'] + df['neg'] + 3)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Group by company and date to ensure daily aggregation\n",
    "grouped_df = news_df.groupby(['company', 'date']).sum().reset_index()\n",
    "\n",
    "# Apply the sentiment calculation\n",
    "Daily_Sentiment_Compound_df = calculate_sentiment_score(grouped_df)\n",
    "\n",
    "\n",
    "Daily_Sentiment_Compound_df = Daily_Sentiment_Compound_df[['company', 'date', 'pos_prob', 'neut_prob', 'neg_prob', 'Sent_d']]\n",
    "\n",
    "Daily_Sentiment_Compound_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: perform the Granger’s causality testing using the dedicated Python library “grangercausalitytests.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'date' column is in datetime format in both dataframes\n",
    "Daily_Sentiment_Compound_df['date'] = pd.to_datetime(Daily_Sentiment_Compound_df['date'])\n",
    "stock_performance_df['date'] = pd.to_datetime(stock_performance_df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the sentiment dataframe with the stock performance dataframe on 'company' and 'date'\n",
    "merged_df = pd.merge(Daily_Sentiment_Compound_df[['company', 'date', 'Sent_d']], \n",
    "                     stock_performance_df[['company', 'date', 'daily_return']], \n",
    "                     on=['company', 'date'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.047750</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.028831</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>-0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "0      Asda 2024-06-07  0.010000     -0.019094\n",
       "1      Asda 2024-07-08  0.052000     -0.005153\n",
       "2      Asda 2024-07-23 -0.043500      0.003829\n",
       "3      Asda 2024-07-24  0.045582     -0.000708\n",
       "4      Asda 2024-07-26 -0.047750     -0.003433\n",
       "..      ...        ...       ...           ...\n",
       "177  Toyota 2024-07-23  0.028831      0.003242\n",
       "178  Toyota 2024-07-24  0.017616     -0.018041\n",
       "179  Toyota 2024-07-25  0.025141     -0.009938\n",
       "180  Toyota 2024-07-26  0.040057     -0.014081\n",
       "181  Toyota 2024-07-29  0.018161     -0.000208\n",
       "\n",
       "[182 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.047750</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>0.028831</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>-0.018041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>-0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>-0.014081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "0      Asda 2024-06-07  0.010000     -0.019094\n",
       "1      Asda 2024-07-08  0.052000     -0.005153\n",
       "2      Asda 2024-07-23 -0.043500      0.003829\n",
       "3      Asda 2024-07-24  0.045582     -0.000708\n",
       "4      Asda 2024-07-26 -0.047750     -0.003433\n",
       "..      ...        ...       ...           ...\n",
       "177  Toyota 2024-07-23  0.028831      0.003242\n",
       "178  Toyota 2024-07-24  0.017616     -0.018041\n",
       "179  Toyota 2024-07-25  0.025141     -0.009938\n",
       "180  Toyota 2024-07-26  0.040057     -0.014081\n",
       "181  Toyota 2024-07-29  0.018161     -0.000208\n",
       "\n",
       "[181 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any rows with missing data, as Granger causality tests require complete cases\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asda</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>-0.047750</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company       date    Sent_d  daily_return\n",
       "0    Asda 2024-06-07  0.010000     -0.019094\n",
       "1    Asda 2024-07-08  0.052000     -0.005153\n",
       "2    Asda 2024-07-23 -0.043500      0.003829\n",
       "3    Asda 2024-07-24  0.045582     -0.000708\n",
       "4    Asda 2024-07-26 -0.047750     -0.003433"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Asda'\n",
    "Toyota_merged_df = merged_df[merged_df['company'] == 'Asda']\n",
    "Toyota_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1501  , p=0.7647  , df_denom=1, df_num=1\n",
      "ssr based chi2 test:   chi2=0.6005  , p=0.4384  , df=1\n",
      "likelihood ratio test: chi2=0.5595  , p=0.4545  , df=1\n",
      "parameter F test:         F=0.1501  , p=0.7647  , df_denom=1, df_num=1\n",
      "Lag 1: p-value = 0.7646763462978328\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for ASDA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Asda_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>0.023492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.013491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>-0.008410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>0.054556</td>\n",
       "      <td>0.032408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ford</td>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>-0.011513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company       date    Sent_d  daily_return\n",
       "5    Ford 2024-05-02  0.061575      0.023492\n",
       "6    Ford 2024-06-20  0.032250      0.013491\n",
       "7    Ford 2024-06-21  0.054579     -0.008410\n",
       "8    Ford 2024-06-24  0.054556      0.032408\n",
       "9    Ford 2024-06-25  0.054730     -0.011513"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Ford'\n",
    "Ford_merged_df = merged_df[merged_df['company'] == 'Ford']\n",
    "Ford_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.8919  , p=0.3568  , df_denom=19, df_num=1\n",
      "ssr based chi2 test:   chi2=1.0327  , p=0.3095  , df=1\n",
      "likelihood ratio test: chi2=1.0092  , p=0.3151  , df=1\n",
      "parameter F test:         F=0.8919  , p=0.3568  , df_denom=19, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.8749  , p=0.4359  , df_denom=16, df_num=2\n",
      "ssr based chi2 test:   chi2=2.2966  , p=0.3172  , df=2\n",
      "likelihood ratio test: chi2=2.1795  , p=0.3363  , df=2\n",
      "parameter F test:         F=0.8749  , p=0.4359  , df_denom=16, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.4632  , p=0.7128  , df_denom=13, df_num=3\n",
      "ssr based chi2 test:   chi2=2.1380  , p=0.5443  , df=3\n",
      "likelihood ratio test: chi2=2.0312  , p=0.5660  , df=3\n",
      "parameter F test:         F=0.4632  , p=0.7128  , df_denom=13, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.7413  , p=0.5851  , df_denom=10, df_num=4\n",
      "ssr based chi2 test:   chi2=5.6336  , p=0.2282  , df=4\n",
      "likelihood ratio test: chi2=4.9338  , p=0.2942  , df=4\n",
      "parameter F test:         F=0.7413  , p=0.5851  , df_denom=10, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.7293  , p=0.6236  , df_denom=7, df_num=5\n",
      "ssr based chi2 test:   chi2=9.3761  , p=0.0950  , df=5\n",
      "likelihood ratio test: chi2=7.5474  , p=0.1830  , df=5\n",
      "parameter F test:         F=0.7293  , p=0.6236  , df_denom=7, df_num=5\n",
      "Lag 1: p-value = 0.35681484732673596\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.43592866903087324\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.7127983355687786\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.5851203659747142\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.6235958203053833\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for FORD\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Ford_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.050563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.013485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.003230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            company       date    Sent_d  daily_return\n",
       "28  Marks & Spencer 2024-05-22  0.057250      0.050563\n",
       "29  Marks & Spencer 2024-05-29  0.042500      0.002646\n",
       "30  Marks & Spencer 2024-05-30  0.039600      0.003626\n",
       "31  Marks & Spencer 2024-06-03  0.052667      0.013485\n",
       "32  Marks & Spencer 2024-06-06  0.036500      0.003230"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Marks & Spencer'\n",
    "MarksSpencer_merged_df = merged_df[merged_df['company'] == 'Marks & Spencer']\n",
    "MarksSpencer_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=4.0383  , p=0.0575  , df_denom=21, df_num=1\n",
      "ssr based chi2 test:   chi2=4.6152  , p=0.0317  , df=1\n",
      "likelihood ratio test: chi2=4.2212  , p=0.0399  , df=1\n",
      "parameter F test:         F=4.0383  , p=0.0575  , df_denom=21, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=5.6899  , p=0.0122  , df_denom=18, df_num=2\n",
      "ssr based chi2 test:   chi2=14.5409 , p=0.0007  , df=2\n",
      "likelihood ratio test: chi2=11.2685 , p=0.0036  , df=2\n",
      "parameter F test:         F=5.6899  , p=0.0122  , df_denom=18, df_num=2\n",
      "Lag 1: p-value = 0.057502848851336406\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.01216209340353528\n",
      "At lag 2, we reject the null hypothesis. Sentiment influences stock market performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for M&S\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 2\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(MarksSpencer_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.022582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.052527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>0.078706</td>\n",
       "      <td>0.057371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>-0.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ocado</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>-0.037378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company       date    Sent_d  daily_return\n",
       "53   Ocado 2024-05-09  0.034750      0.022582\n",
       "54   Ocado 2024-07-08  0.004000      0.052527\n",
       "55   Ocado 2024-07-16  0.078706      0.057371\n",
       "56   Ocado 2024-07-17  0.059000     -0.008357\n",
       "57   Ocado 2024-07-19 -0.001750     -0.037378"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Ocado'\n",
    "Ocado_merged_df = merged_df[merged_df['company'] == 'Ocado']\n",
    "Ocado_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=4.5661  , p=0.0857  , df_denom=5, df_num=1\n",
      "ssr based chi2 test:   chi2=7.3058  , p=0.0069  , df=1\n",
      "likelihood ratio test: chi2=5.1903  , p=0.0227  , df=1\n",
      "parameter F test:         F=4.5661  , p=0.0857  , df_denom=5, df_num=1\n",
      "Lag 1: p-value = 0.08565825178491664\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for OCADO\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Ocado_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.025477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Polestar</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.048391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company       date    Sent_d  daily_return\n",
       "62  Polestar 2024-06-05  0.027143      0.025477\n",
       "63  Polestar 2024-06-28 -0.009143     -0.048391"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Polestar'\n",
    "Polestar_merged_df = merged_df[merged_df['company'] == 'Polestar']\n",
    "Polestar_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient observations. Maximum allowable lag is -1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m max_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m granger_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrangercausalitytests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPolestar_merged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSent_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print summary of the test results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag, test_result \u001b[38;5;129;01min\u001b[39;00m granger_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1567\u001b[0m, in \u001b[0;36mgrangercausalitytests\u001b[0;34m(x, maxlag, addconst, verbose)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag must be a non-empty list containing only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive integers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1564\u001b[0m         )\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst):\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient observations. Maximum allowable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1570\u001b[0m     )\n\u001b[1;32m   1572\u001b[0m resli \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mlg \u001b[38;5;129;01min\u001b[39;00m lags:\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient observations. Maximum allowable lag is -1"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for POLESTAR\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Polestar_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>-0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.010921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>-0.014406</td>\n",
       "      <td>-0.029124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sainsburys</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.018962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date    Sent_d  daily_return\n",
       "64  Sainsburys 2024-06-12  0.033500     -0.002337\n",
       "65  Sainsburys 2024-07-01  0.090500      0.010921\n",
       "66  Sainsburys 2024-07-02 -0.014406     -0.029124\n",
       "67  Sainsburys 2024-07-16  0.041500      0.018962"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Sainsburys'\n",
    "Sainsburys_merged_df = merged_df[merged_df['company'] == 'Sainsburys']\n",
    "Sainsburys_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient observations. Maximum allowable lag is 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m max_lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m granger_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrangercausalitytests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSainsburys_merged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSent_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print summary of the test results\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag, test_result \u001b[38;5;129;01min\u001b[39;00m granger_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1567\u001b[0m, in \u001b[0;36mgrangercausalitytests\u001b[0;34m(x, maxlag, addconst, verbose)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag must be a non-empty list containing only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive integers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1564\u001b[0m         )\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst):\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient observations. Maximum allowable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlag is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(addconst)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1570\u001b[0m     )\n\u001b[1;32m   1572\u001b[0m resli \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mlg \u001b[38;5;129;01min\u001b[39;00m lags:\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient observations. Maximum allowable lag is 0"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for SAINSBURY'S\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 1\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Sainsburys_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.017366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>-0.004931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>-0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.036315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Stellantis</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.020707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company       date    Sent_d  daily_return\n",
       "68  Stellantis 2024-05-03  0.021000      0.017366\n",
       "69  Stellantis 2024-05-06 -0.016750     -0.004931\n",
       "70  Stellantis 2024-05-07  0.033193     -0.001484\n",
       "71  Stellantis 2024-05-13  0.004500      0.036315\n",
       "72  Stellantis 2024-05-14  0.077600      0.020707"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Stellantis'\n",
    "Stellantis_merged_df = merged_df[merged_df['company'] == 'Stellantis']\n",
    "Stellantis_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1345  , p=0.7197  , df_denom=13, df_num=1\n",
      "ssr based chi2 test:   chi2=0.1656  , p=0.6841  , df=1\n",
      "likelihood ratio test: chi2=0.1647  , p=0.6848  , df=1\n",
      "parameter F test:         F=0.1345  , p=0.7197  , df_denom=13, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.0514  , p=0.9502  , df_denom=10, df_num=2\n",
      "ssr based chi2 test:   chi2=0.1541  , p=0.9258  , df=2\n",
      "likelihood ratio test: chi2=0.1534  , p=0.9262  , df=2\n",
      "parameter F test:         F=0.0514  , p=0.9502  , df_denom=10, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.0655  , p=0.9765  , df_denom=7, df_num=3\n",
      "ssr based chi2 test:   chi2=0.3930  , p=0.9417  , df=3\n",
      "likelihood ratio test: chi2=0.3876  , p=0.9428  , df=3\n",
      "parameter F test:         F=0.0655  , p=0.9765  , df_denom=7, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.2377  , p=0.9035  , df_denom=4, df_num=4\n",
      "ssr based chi2 test:   chi2=3.0900  , p=0.5429  , df=4\n",
      "likelihood ratio test: chi2=2.7722  , p=0.5966  , df=4\n",
      "parameter F test:         F=0.2377  , p=0.9035  , df_denom=4, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.4064  , p=0.8225  , df_denom=1, df_num=5\n",
      "ssr based chi2 test:   chi2=24.3821 , p=0.0002  , df=5\n",
      "likelihood ratio test: chi2=13.3100 , p=0.0206  , df=5\n",
      "parameter F test:         F=0.4064  , p=0.8225  , df_denom=1, df_num=5\n",
      "Lag 1: p-value = 0.7196632703544441\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.9501638075270157\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.9764772954586767\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.903522334459006\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.8224922607585095\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for STELLANTIS\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Stellantis_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>-0.005016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>-0.010750</td>\n",
       "      <td>0.007767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>-0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Tesco</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.001610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company       date    Sent_d  daily_return\n",
       "85   Tesco 2024-05-03  0.046250     -0.005016\n",
       "86   Tesco 2024-05-09 -0.010750      0.007767\n",
       "87   Tesco 2024-05-14  0.058000      0.004150\n",
       "88   Tesco 2024-05-15  0.023200     -0.010247\n",
       "89   Tesco 2024-05-20 -0.004251     -0.001610"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Tesco'\n",
    "Tesco_merged_df = merged_df[merged_df['company'] == 'Tesco']\n",
    "Tesco_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1936  , p=0.6636  , df_denom=26, df_num=1\n",
      "ssr based chi2 test:   chi2=0.2159  , p=0.6421  , df=1\n",
      "likelihood ratio test: chi2=0.2151  , p=0.6428  , df=1\n",
      "parameter F test:         F=0.1936  , p=0.6636  , df_denom=26, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.5928  , p=0.5610  , df_denom=23, df_num=2\n",
      "ssr based chi2 test:   chi2=1.4433  , p=0.4859  , df=2\n",
      "likelihood ratio test: chi2=1.4073  , p=0.4948  , df=2\n",
      "parameter F test:         F=0.5928  , p=0.5610  , df_denom=23, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.3637  , p=0.7799  , df_denom=20, df_num=3\n",
      "ssr based chi2 test:   chi2=1.4729  , p=0.6885  , df=3\n",
      "likelihood ratio test: chi2=1.4341  , p=0.6976  , df=3\n",
      "parameter F test:         F=0.3637  , p=0.7799  , df_denom=20, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.1790  , p=0.9462  , df_denom=17, df_num=4\n",
      "ssr based chi2 test:   chi2=1.0948  , p=0.8951  , df=4\n",
      "likelihood ratio test: chi2=1.0724  , p=0.8986  , df=4\n",
      "parameter F test:         F=0.1790  , p=0.9462  , df_denom=17, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.1041  , p=0.9896  , df_denom=14, df_num=5\n",
      "ssr based chi2 test:   chi2=0.9298  , p=0.9680  , df=5\n",
      "likelihood ratio test: chi2=0.9129  , p=0.9693  , df=5\n",
      "parameter F test:         F=0.1041  , p=0.9896  , df_denom=14, df_num=5\n",
      "Lag 1: p-value = 0.6635663342788318\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.5610112691986853\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.7799220933529813\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.946163162299277\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.9896013932785162\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TESCO\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 5\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Tesco_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.017531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>-0.020562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>-0.003250</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>-0.022750</td>\n",
       "      <td>0.014874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>0.088167</td>\n",
       "      <td>-0.014245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "115   Tesla 2024-05-08 -0.000250     -0.017531\n",
       "116   Tesla 2024-05-10  0.001667     -0.020562\n",
       "117   Tesla 2024-05-14 -0.003250      0.032398\n",
       "118   Tesla 2024-05-17 -0.022750      0.014874\n",
       "119   Tesla 2024-05-20  0.088167     -0.014245"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Tesla'\n",
    "Tesla_merged_df = merged_df[merged_df['company'] == 'Tesla']\n",
    "Tesla_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.3368  , p=0.5657  , df_denom=32, df_num=1\n",
      "ssr based chi2 test:   chi2=0.3684  , p=0.5439  , df=1\n",
      "likelihood ratio test: chi2=0.3665  , p=0.5449  , df=1\n",
      "parameter F test:         F=0.3368  , p=0.5657  , df_denom=32, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.4126  , p=0.1073  , df_denom=29, df_num=2\n",
      "ssr based chi2 test:   chi2=5.6571  , p=0.0591  , df=2\n",
      "likelihood ratio test: chi2=5.2329  , p=0.0731  , df=2\n",
      "parameter F test:         F=2.4126  , p=0.1073  , df_denom=29, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.5877  , p=0.0271  , df_denom=26, df_num=3\n",
      "ssr based chi2 test:   chi2=13.6610 , p=0.0034  , df=3\n",
      "likelihood ratio test: chi2=11.4313 , p=0.0096  , df=3\n",
      "parameter F test:         F=3.5877  , p=0.0271  , df_denom=26, df_num=3\n",
      "Lag 1: p-value = 0.5657438251775035\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.10734602644554873\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.027090163564218627\n",
      "At lag 3, we reject the null hypothesis. Sentiment influences stock market performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TESLA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 3\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Tesla_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>Sent_d</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>0.095889</td>\n",
       "      <td>0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>0.046738</td>\n",
       "      <td>0.011130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.008633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>0.074167</td>\n",
       "      <td>-0.022050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company       date    Sent_d  daily_return\n",
       "152  Toyota 2024-05-02  0.095889      0.017351\n",
       "153  Toyota 2024-05-14  0.071400      0.006840\n",
       "154  Toyota 2024-05-15  0.046738      0.011130\n",
       "155  Toyota 2024-05-28  0.045900      0.008633\n",
       "156  Toyota 2024-05-29  0.074167     -0.022050"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset for rows where 'company' is 'Toyota'\n",
    "Toyota_merged_df = merged_df[merged_df['company'] == 'Toyota']\n",
    "Toyota_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.8919  , p=0.3568  , df_denom=19, df_num=1\n",
      "ssr based chi2 test:   chi2=1.0327  , p=0.3095  , df=1\n",
      "likelihood ratio test: chi2=1.0092  , p=0.3151  , df=1\n",
      "parameter F test:         F=0.8919  , p=0.3568  , df_denom=19, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.8749  , p=0.4359  , df_denom=16, df_num=2\n",
      "ssr based chi2 test:   chi2=2.2966  , p=0.3172  , df=2\n",
      "likelihood ratio test: chi2=2.1795  , p=0.3363  , df=2\n",
      "parameter F test:         F=0.8749  , p=0.4359  , df_denom=16, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.4632  , p=0.7128  , df_denom=13, df_num=3\n",
      "ssr based chi2 test:   chi2=2.1380  , p=0.5443  , df=3\n",
      "likelihood ratio test: chi2=2.0312  , p=0.5660  , df=3\n",
      "parameter F test:         F=0.4632  , p=0.7128  , df_denom=13, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.7413  , p=0.5851  , df_denom=10, df_num=4\n",
      "ssr based chi2 test:   chi2=5.6336  , p=0.2282  , df=4\n",
      "likelihood ratio test: chi2=4.9338  , p=0.2942  , df=4\n",
      "parameter F test:         F=0.7413  , p=0.5851  , df_denom=10, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.7293  , p=0.6236  , df_denom=7, df_num=5\n",
      "ssr based chi2 test:   chi2=9.3761  , p=0.0950  , df=5\n",
      "likelihood ratio test: chi2=7.5474  , p=0.1830  , df=5\n",
      "parameter F test:         F=0.7293  , p=0.6236  , df_denom=7, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.0979  , p=0.4861  , df_denom=4, df_num=6\n",
      "ssr based chi2 test:   chi2=27.9976 , p=0.0001  , df=6\n",
      "likelihood ratio test: chi2=16.5477 , p=0.0111  , df=6\n",
      "parameter F test:         F=1.0979  , p=0.4861  , df_denom=4, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=3.5218  , p=0.3894  , df_denom=1, df_num=7\n",
      "ssr based chi2 test:   chi2=394.4458, p=0.0000  , df=7\n",
      "likelihood ratio test: chi2=51.9145 , p=0.0000  , df=7\n",
      "parameter F test:         F=3.5218  , p=0.3894  , df_denom=1, df_num=7\n",
      "Lag 1: p-value = 0.35681484732673596\n",
      "At lag 1, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 2: p-value = 0.43592866903087324\n",
      "At lag 2, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 3: p-value = 0.7127983355687786\n",
      "At lag 3, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 4: p-value = 0.5851203659747142\n",
      "At lag 4, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 5: p-value = 0.6235958203053833\n",
      "At lag 5, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 6: p-value = 0.4861157520526052\n",
      "At lag 6, we fail to reject the null hypothesis.\n",
      "\n",
      "Lag 7: p-value = 0.3893806885393748\n",
      "At lag 7, we fail to reject the null hypothesis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Granger causality test for TOYOTA\n",
    "# Set the maximum number of lags to test\n",
    "max_lag = 7\n",
    "\n",
    "# Perform Granger causality test to see if Sent_d (sentiment) Granger-causes daily_return (market performance)\n",
    "granger_results = grangercausalitytests(Toyota_merged_df[['daily_return','Sent_d']], max_lag)\n",
    "\n",
    "# Print summary of the test results\n",
    "for lag, test_result in granger_results.items():\n",
    "    p_value = test_result[0]['ssr_ftest'][1]  # Extract the p-value for each lag's F-test\n",
    "    print(f\"Lag {lag}: p-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"At lag {lag}, we reject the null hypothesis. Sentiment influences stock market performance.\\n\")\n",
    "    else:\n",
    "        print(f\"At lag {lag}, we fail to reject the null hypothesis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of available data points per company\n",
    "available_data_counts = merged_df.groupby('company').size().reset_index(name='available_data_points')\n",
    "\n",
    "# Merge the total days with available data counts\n",
    "result_df = pd.merge(total_days_df[['company', 'total_days']], available_data_counts, on='company')\n",
    "\n",
    "# Calculate the percentage of available data\n",
    "result_df['percentage_available'] = (result_df['available_data_points'] / result_df['total_days']) * 100\n",
    "\n",
    "# Display the result\n",
    "print(result_df[['company', 'total_days', 'available_data_points', 'percentage_available']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  total_days  available_data_points  percentage_available\n",
      "0             Asda          92                      5              5.434783\n",
      "1             Ford          92                     23             25.000000\n",
      "2  Marks & Spencer          92                     25             27.173913\n",
      "3            Ocado          92                      9              9.782609\n",
      "4         Polestar          92                      2              2.173913\n",
      "5       Sainsburys          92                      4              4.347826\n",
      "6       Stellantis          92                     17             18.478261\n",
      "7            Tesco          92                     30             32.608696\n",
      "8            Tesla          92                     36             39.130435\n",
      "9           Toyota          92                     30             32.608696\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format if not already\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "# Count the number of available data points per company\n",
    "available_data_counts = merged_df.groupby('company').size().reset_index(name='available_data_points')\n",
    "\n",
    "# Add the total_days column with the same value for all companies\n",
    "available_data_counts['total_days'] = N\n",
    "\n",
    "# Calculate the percentage of available data\n",
    "available_data_counts['percentage_available'] = (available_data_counts['available_data_points'] / available_data_counts['total_days']) * 100\n",
    "\n",
    "# Display the result\n",
    "print(available_data_counts[['company', 'total_days', 'available_data_points', 'percentage_available']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: M&S and Tesla show correlation between sentiment and returns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new insight mamps revealing 10 population conf...</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>working repair alterations specialist sojo uk ...</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk retailer marks spencer tells style currentl...</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>esg</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new insight mamps revealing 10 population conf...</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>working repair alterations specialist sojo uk ...</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date  \\\n",
       "0  new insight mamps revealing 10 population conf...  2024-07-04   \n",
       "1  working repair alterations specialist sojo uk ...  2024-07-02   \n",
       "2  uk retailer marks spencer tells style currentl...  2024-06-21   \n",
       "3  new insight mamps revealing 10 population conf...  2024-07-04   \n",
       "4  working repair alterations specialist sojo uk ...  2024-07-02   \n",
       "\n",
       "           company       ticker    neg    neu    pos  compound sentiment  \n",
       "0  Marks & Spencer          esg  0.039  0.809  0.152    0.9947  positive  \n",
       "1  Marks & Spencer          esg  0.009  0.864  0.127    0.9853  positive  \n",
       "2  Marks & Spencer          esg  0.048  0.846  0.106    0.9274  positive  \n",
       "3  Marks & Spencer  environment  0.039  0.809  0.152    0.9947  positive  \n",
       "4  Marks & Spencer  environment  0.009  0.864  0.127    0.9853  positive  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extrapolate the pre-processed news articles for M&S only\n",
    "Marks_Spencer_news_df = news_df[news_df['company'] == 'Marks & Spencer'].reset_index(drop=True)\n",
    "Marks_Spencer_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>date</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new insight mamps revealing 10 population conf...</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>working repair alterations specialist sojo uk ...</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk retailer marks spencer tells style currentl...</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new insight mamps revealing 10 population conf...</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>working repair alterations specialist sojo uk ...</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>Marks &amp; Spencer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story        date  \\\n",
       "0  new insight mamps revealing 10 population conf...  2024-07-04   \n",
       "1  working repair alterations specialist sojo uk ...  2024-07-02   \n",
       "2  uk retailer marks spencer tells style currentl...  2024-06-21   \n",
       "3  new insight mamps revealing 10 population conf...  2024-07-04   \n",
       "4  working repair alterations specialist sojo uk ...  2024-07-02   \n",
       "\n",
       "           company  \n",
       "0  Marks & Spencer  \n",
       "1  Marks & Spencer  \n",
       "2  Marks & Spencer  \n",
       "3  Marks & Spencer  \n",
       "4  Marks & Spencer  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Marks_Spencer_news_df = Marks_Spencer_news_df[['story','date','company']]\n",
    "Marks_Spencer_news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Preprocessed Data into Document-Term Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the CountVectorizer from scikit-learn to transform \n",
    "# the preprocessed news articles into a document-term matrix.\n",
    "# Vectoriser expects a list. Let's convert the content of the column\n",
    "# 'story' as a list of strings\n",
    "\n",
    "news_list = Marks_Spencer_news_df['story'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                    56\n",
       "unique                                                   46\n",
       "top       new insight mamps revealing 10 population conf...\n",
       "freq                                                      4\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(news_list)\n",
    "s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "dtm = vectorizer.fit_transform(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 10905 stored elements and shape (56, 4204)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's use gensim to create an LDA model. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Specify the number of topics (n_topics), and fit the model to the document-term matrix.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpora\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Let's use gensim to create an LDA model. \n",
    "# Specify the number of topics (n_topics), and fit the model to the document-term matrix.\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: The Latent Dirichlet Allocation (LDA) model will be implemented\n",
    "using dedicated Python libraries such as Gensim which is a library for topic modeling and natural language processing. Below are the indicative steps that will be\n",
    "followed to build an LDA model:\n",
    "- Create a dataset containing news stories;\n",
    "- Perform text preprocessing by tokenising and cleaning the text;\n",
    "- Generate a few LDA models using different topic values, then verify how\n",
    "these models perform in the supervised classification model training\n",
    "(Kelechava 2019);\n",
    "- Visualise the topics generated with the words associated with each topic,\n",
    "and\n",
    "- Transform the original texts (the headlines) to the topic vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Finally, the topic vectors will be fed into a classifier and the process validated\n",
    "by splitting the topic dataframe into train and test to simulate how the model\n",
    "would perform with a new set of data. The classification report will be generated\n",
    "to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Objctive 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[0;32m~/Documents/02_Uni/02_BBK/09_FinalProject/MyMScReportRepo/myprojenv/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(gensim.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myprojenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
